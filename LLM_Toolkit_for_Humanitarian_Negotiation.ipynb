{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPkvVTXd6y4OkzpWeiUa/fB",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/escenariosparalatransformacion/Chat-Rag/blob/main/LLM_Toolkit_for_Humanitarian_Negotiation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "cellView": "form",
        "id": "sZZ--EGm5899",
        "outputId": "f63e267e-aac4-468b-b318-3e77b353a2e3"
      },
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "⏳ Installing dependencies...\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m89.9/89.9 kB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.0/62.0 kB\u001b[0m \u001b[31m956.2 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.5/46.5 MB\u001b[0m \u001b[31m18.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m322.2/322.2 kB\u001b[0m \u001b[31m19.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m243.4/243.4 kB\u001b[0m \u001b[31m16.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m413.7/413.7 kB\u001b[0m \u001b[31m21.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m288.7/288.7 kB\u001b[0m \u001b[31m8.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.1/13.1 MB\u001b[0m \u001b[31m74.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.4/16.4 MB\u001b[0m \u001b[31m55.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.6/8.6 MB\u001b[0m \u001b[31m57.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m95.2/95.2 kB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.3/11.3 MB\u001b[0m \u001b[31m68.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m72.0/72.0 kB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.3/62.3 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "google-colab 1.0.0 requires pandas==2.2.2, but you have pandas 2.2.3 which is incompatible.\n",
            "numba 0.60.0 requires numpy<2.1,>=1.22, but you have numpy 2.2.4 which is incompatible.\n",
            "tensorflow 2.18.0 requires numpy<2.1.0,>=1.26.0, but you have numpy 2.2.4 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m✅ Dependencies installed.\n",
            "✅ Utility functions and API callers defined.\n",
            "⏳ Creating Gradio interface...\n",
            "❌ MTP file not found: mtp_examples.json\n",
            "✅ Created default MTP file\n",
            "✅ Gradio interface created.\n",
            "🚀 Launching Gradio application...\n",
            "Colab notebook detected. This cell will run indefinitely so that you can see errors and logs. To turn off, set debug=False in launch().\n",
            "* Running on public URL: https://b2dc39c5e4e8366ff5.gradio.live\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div><iframe src=\"https://b2dc39c5e4e8366ff5.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# @title Cell 1: Install Dependencies\n",
        "# ---\n",
        "# Execute this cell first to install necessary libraries.\n",
        "# ---\n",
        "print(\"⏳ Installing dependencies...\")\n",
        "# -U ensures packages are updated if already installed\n",
        "!pip install -q -U gradio openai google-generativeai anthropic elevenlabs requests python-dotenv mistralai pandas numpy matplotlib pyttsx3\n",
        "print(\"✅ Dependencies installed.\")\n",
        "\n",
        "# @title Cell 2: Utility Functions & API Calls (Real)\n",
        "# ---\n",
        "# Defines functions for Gradio components.\n",
        "# Includes REAL API calls and instructions for local services (Ollama, n8n).\n",
        "# All comments and docstrings are in English.\n",
        "# ---\n",
        "import gradio as gr\n",
        "import os\n",
        "import requests\n",
        "import time\n",
        "import base64\n",
        "import json\n",
        "import subprocess\n",
        "from datetime import datetime\n",
        "from dotenv import load_dotenv\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from pathlib import Path # For saving audio files\n",
        "import pyttsx3 # For local text-to-speech (fallback)\n",
        "\n",
        "# Load environment variables if a .env file exists (useful for local development)\n",
        "load_dotenv()\n",
        "\n",
        "# --- Cloud LLM API Call Functions (REAL) ---\n",
        "\n",
        "def call_openai_api(api_key, prompt_text, model=\"gpt-4o-mini\", system_message=\"You are a helpful assistant specialized in humanitarian negotiation analysis.\"):\n",
        "    \"\"\"\n",
        "    Makes a real API call to OpenAI (ChatGPT).\n",
        "\n",
        "    Args:\n",
        "        api_key (str): OpenAI API key.\n",
        "        prompt_text (str): The prompt to send to the model.\n",
        "        model (str): The OpenAI model to use.\n",
        "        system_message (str): System message to control assistant behavior.\n",
        "\n",
        "    Returns:\n",
        "        str: The response text from the model or an error message.\n",
        "    \"\"\"\n",
        "    if not api_key:\n",
        "        return \"❌ Error: OpenAI API key not provided.\"\n",
        "    try:\n",
        "        from openai import OpenAI, AuthenticationError, APIError\n",
        "        client = OpenAI(api_key=api_key)\n",
        "        response = client.chat.completions.create(\n",
        "            model=model,\n",
        "            messages=[\n",
        "                {\"role\": \"system\", \"content\": system_message},\n",
        "                {\"role\": \"user\", \"content\": prompt_text}\n",
        "            ]\n",
        "        )\n",
        "        return response.choices[0].message.content\n",
        "    except ImportError:\n",
        "        return \"❌ Error: 'openai' library not found. Please ensure Cell 1 ran successfully.\"\n",
        "    except AuthenticationError:\n",
        "         return f\"❌ OpenAI Authentication Error: Invalid API key or insufficient permissions.\"\n",
        "    except APIError as e:\n",
        "         return f\"❌ OpenAI API Error: {e}\"\n",
        "    except Exception as e:\n",
        "        return f\"❌ An unexpected error occurred calling OpenAI: {e}\"\n",
        "\n",
        "def call_gemini_api(api_key, prompt_text, model=\"gemini-1.5-flash-latest\"):\n",
        "    \"\"\"\n",
        "    Makes a real API call to Google AI (Gemini).\n",
        "\n",
        "    Args:\n",
        "        api_key (str): Google AI API key.\n",
        "        prompt_text (str): The prompt to send to the model.\n",
        "        model (str): The Gemini model to use.\n",
        "\n",
        "    Returns:\n",
        "        str: The response text from the model or an error message.\n",
        "    \"\"\"\n",
        "    if not api_key:\n",
        "        return \"❌ Error: Gemini API key not provided.\"\n",
        "    try:\n",
        "        import google.generativeai as genai\n",
        "        from google.api_core import exceptions as google_exceptions # For specific errors\n",
        "\n",
        "        genai.configure(api_key=api_key)\n",
        "        gen_model = genai.GenerativeModel(model)\n",
        "        response = gen_model.generate_content(prompt_text)\n",
        "\n",
        "        # Handle potential blocking or empty responses\n",
        "        if not response.parts:\n",
        "            try:\n",
        "                if response.prompt_feedback and response.prompt_feedback.block_reason:\n",
        "                    return (f\"❌ Content blocked by Gemini. \"\n",
        "                            f\"Reason: {response.prompt_feedback.block_reason}. \"\n",
        "                            f\"Message: {response.prompt_feedback.block_reason_message}\")\n",
        "                elif response.candidates and response.candidates[0].finish_reason != 'STOP':\n",
        "                    # Handle other finish reasons like SAFETY, RECITATION etc.\n",
        "                    safety_ratings_str = str(getattr(response.candidates[0], 'safety_ratings', 'N/A'))\n",
        "                    return (f\"❌ Gemini response stopped. \"\n",
        "                            f\"Reason: {response.candidates[0].finish_reason}. \"\n",
        "                            f\"Safety Ratings: {safety_ratings_str}\")\n",
        "                else:\n",
        "                    return \"❌ Gemini returned an empty response for an unknown reason.\"\n",
        "            except (AttributeError, IndexError):\n",
        "                 return f\"❌ Gemini returned an empty or blocked response (unexpected structure). Full response: {response}\"\n",
        "            except Exception as e:\n",
        "                 return f\"❌ Error parsing Gemini blocked response details: {e}. Full response: {response}\"\n",
        "\n",
        "        return response.text\n",
        "    except ImportError:\n",
        "        return \"❌ Error: 'google-generativeai' library not found. Please ensure Cell 1 ran successfully.\"\n",
        "    except google_exceptions.PermissionDenied:\n",
        "         return f\"❌ Google AI Permission Denied: Invalid API key or API not enabled.\"\n",
        "    except google_exceptions.ResourceExhausted:\n",
        "         return f\"❌ Google AI Quota Exceeded: You have exceeded your usage limit.\"\n",
        "    except Exception as e:\n",
        "        return f\"❌ An unexpected error occurred calling Gemini: {e}\"\n",
        "\n",
        "def call_claude_api(api_key, prompt_text, model=\"claude-3-haiku-20240307\", system_message=\"You are a helpful assistant specialized in humanitarian negotiation analysis.\"):\n",
        "    \"\"\"\n",
        "    Makes a real API call to Anthropic (Claude).\n",
        "\n",
        "    Args:\n",
        "        api_key (str): Anthropic API key.\n",
        "        prompt_text (str): The prompt to send to the model.\n",
        "        model (str): The Claude model to use.\n",
        "        system_message (str): System message to control assistant behavior.\n",
        "\n",
        "    Returns:\n",
        "        str: The response text from the model or an error message.\n",
        "    \"\"\"\n",
        "    if not api_key:\n",
        "        return \"❌ Error: Anthropic API key not provided.\"\n",
        "    try:\n",
        "        from anthropic import Anthropic, AuthenticationError, APIError\n",
        "        client = Anthropic(api_key=api_key)\n",
        "        message = client.messages.create(\n",
        "            model=model,\n",
        "            max_tokens=4096,  # Increased token limit for complex scenarios\n",
        "            system=system_message,\n",
        "            messages=[\n",
        "                {\n",
        "                    \"role\": \"user\",\n",
        "                    \"content\": prompt_text\n",
        "                }\n",
        "            ]\n",
        "        )\n",
        "        response_text = \"\"\n",
        "        if message.content:\n",
        "            for block in message.content:\n",
        "                if block.type == \"text\":\n",
        "                    response_text += block.text\n",
        "\n",
        "        if not response_text and message.stop_reason:\n",
        "            return f\"⚠️ Claude response empty. Stop Reason: {message.stop_reason}\"\n",
        "        elif not response_text:\n",
        "             return \"⚠️ Claude returned an empty response for an unknown reason.\"\n",
        "\n",
        "        return response_text\n",
        "    except ImportError:\n",
        "        return \"❌ Error: 'anthropic' library not found. Please ensure Cell 1 ran successfully.\"\n",
        "    except AuthenticationError:\n",
        "         return f\"❌ Anthropic Authentication Error: Invalid API key.\"\n",
        "    except APIError as e:\n",
        "         return f\"❌ Anthropic API Error: {e}\"\n",
        "    except Exception as e:\n",
        "        return f\"❌ An unexpected error occurred calling Claude: {e}\"\n",
        "\n",
        "def call_mistral_api(api_key, prompt_text, model=\"mistral-small-latest\"):\n",
        "    \"\"\"\n",
        "    Makes a real API call to Mistral AI.\n",
        "\n",
        "    Args:\n",
        "        api_key (str): Mistral AI API key.\n",
        "        prompt_text (str): The prompt to send to the model.\n",
        "        model (str): The Mistral model to use.\n",
        "\n",
        "    Returns:\n",
        "        str: The response text from the model or an error message.\n",
        "    \"\"\"\n",
        "    if not api_key:\n",
        "        return \"❌ Error: Mistral API key not provided.\"\n",
        "    try:\n",
        "        from mistralai.client import MistralClient\n",
        "        from mistralai.models.chat_completion import ChatMessage\n",
        "        from mistralai.exceptions import MistralAPIException, MistralConnectionException\n",
        "\n",
        "        client = MistralClient(api_key=api_key)\n",
        "        chat_response = client.chat(\n",
        "            model=model,\n",
        "            messages=[ChatMessage(role=\"user\", content=prompt_text)]\n",
        "        )\n",
        "        return chat_response.choices[0].message.content\n",
        "    except ImportError:\n",
        "        return \"❌ Error: 'mistralai' library not found. Please ensure Cell 1 ran successfully.\"\n",
        "    except MistralAPIException as e:\n",
        "         # Handle specific Mistral errors, e.g., authentication, rate limits\n",
        "         return f\"❌ Mistral API Error: {e}\"\n",
        "    except MistralConnectionException as e:\n",
        "         return f\"❌ Mistral Connection Error: {e}\"\n",
        "    except Exception as e:\n",
        "        return f\"❌ An unexpected error occurred calling Mistral: {e}\"\n",
        "\n",
        "def call_huggingface_api(api_key, prompt_text, model=\"mistralai/Mistral-7B-Instruct-v0.2\"):\n",
        "    \"\"\"\n",
        "    Makes a real API call to Hugging Face Inference API.\n",
        "\n",
        "    Args:\n",
        "        api_key (str): Hugging Face API key.\n",
        "        prompt_text (str): The prompt to send to the model.\n",
        "        model (str): The model to use via Hugging Face.\n",
        "\n",
        "    Returns:\n",
        "        str: The response text from the model or an error message.\n",
        "    \"\"\"\n",
        "    if not api_key:\n",
        "        return \"❌ Error: Hugging Face API key not provided.\"\n",
        "\n",
        "    API_URL = f\"https://api-inference.huggingface.co/models/{model}\"\n",
        "    headers = {\"Authorization\": f\"Bearer {api_key}\"}\n",
        "\n",
        "    try:\n",
        "        payload = {\n",
        "            \"inputs\": prompt_text,\n",
        "            \"parameters\": {\n",
        "                \"max_new_tokens\": 1024,\n",
        "                \"temperature\": 0.7,\n",
        "                \"top_p\": 0.95,\n",
        "                \"do_sample\": True\n",
        "            }\n",
        "        }\n",
        "\n",
        "        response = requests.post(API_URL, headers=headers, json=payload)\n",
        "\n",
        "        if response.status_code == 200:\n",
        "            result = response.json()\n",
        "            # Different models might have different response structures\n",
        "            if isinstance(result, list) and len(result) > 0:\n",
        "                if \"generated_text\" in result[0]:\n",
        "                    return result[0][\"generated_text\"]\n",
        "            elif isinstance(result, dict):\n",
        "                if \"generated_text\" in result:\n",
        "                    return result[\"generated_text\"]\n",
        "\n",
        "            # Fallback if we can't find the expected structure\n",
        "            return str(result)\n",
        "        else:\n",
        "            return f\"❌ Hugging Face API Error: {response.status_code}, {response.text}\"\n",
        "\n",
        "    except Exception as e:\n",
        "        return f\"❌ An unexpected error occurred calling Hugging Face: {e}\"\n",
        "\n",
        "# --- Local LLM API Call Function (REAL - Requires Local Ollama) ---\n",
        "\n",
        "def call_ollama_api(model_name, prompt_text, ollama_base_url=\"http://localhost:11434\"):\n",
        "    \"\"\"\n",
        "    Makes a real API call to a locally running Ollama instance.\n",
        "\n",
        "    Args:\n",
        "        model_name (str): The name of the Ollama model to use (e.g., 'llama3:8b').\n",
        "        prompt_text (str): The prompt to send to the model.\n",
        "        ollama_base_url (str): The base URL of the Ollama API endpoint.\n",
        "\n",
        "    Returns:\n",
        "        str: The response text from the model or an error message.\n",
        "    \"\"\"\n",
        "    if not model_name:\n",
        "        return \"❌ Error: Ollama model name not provided.\"\n",
        "    if not prompt_text:\n",
        "        return \"⚠️ Warning: Prompt is empty.\"\n",
        "\n",
        "    api_url = f\"{ollama_base_url.rstrip('/')}/api/generate\"\n",
        "    payload = {\n",
        "        \"model\": model_name,\n",
        "        \"prompt\": prompt_text,\n",
        "        \"stream\": False # Get the full response at once\n",
        "    }\n",
        "    headers = {'Content-Type': 'application/json'}\n",
        "\n",
        "    try:\n",
        "        print(f\"ℹ️ Attempting to contact Ollama at {api_url} with model '{model_name}'...\")\n",
        "        response = requests.post(api_url, json=payload, headers=headers, timeout=120) # Increased timeout\n",
        "        response.raise_for_status() # Raise HTTPError for bad responses (4xx or 5xx)\n",
        "\n",
        "        response_data = response.json()\n",
        "        # Check if the 'response' key exists\n",
        "        if 'response' in response_data:\n",
        "            return response_data['response'].strip()\n",
        "        elif 'error' in response_data:\n",
        "             # Handle cases where Ollama itself returns an error (e.g., model not found)\n",
        "             return f\"❌ Ollama API Error: {response_data['error']}\"\n",
        "        else:\n",
        "             # Handle unexpected response structure\n",
        "             return f\"❌ Ollama Error: Unexpected response format. Full response: {response_data}\"\n",
        "\n",
        "    except requests.exceptions.ConnectionError:\n",
        "        return (f\"❌ Connection Error: Could not connect to Ollama at {ollama_base_url}. \"\n",
        "                f\"Ensure Ollama is installed, running, and accessible from where you run this script. \"\n",
        "                f\"If running Gradio in Colab, you might need tunneling (e.g., cloudflared) or run Gradio locally.\")\n",
        "    except requests.exceptions.Timeout:\n",
        "        return f\"❌ Timeout Error: The request to Ollama at {api_url} timed out.\"\n",
        "    except requests.exceptions.RequestException as e:\n",
        "        # Catch other potential request errors\n",
        "        return f\"❌ Request Error: An error occurred contacting Ollama: {e}\"\n",
        "    except json.JSONDecodeError:\n",
        "        return f\"❌ Ollama Error: Could not decode JSON response from Ollama. Response text: {response.text}\"\n",
        "    except Exception as e:\n",
        "        # Catch any other unexpected errors\n",
        "        return f\"❌ An unexpected error occurred calling Ollama: {e}\"\n",
        "\n",
        "# Alternative method using subprocess if Ollama API approach doesn't work\n",
        "def call_ollama_subprocess(model_name, prompt_text):\n",
        "    \"\"\"\n",
        "    Uses subprocess to call Ollama CLI directly (alternative method).\n",
        "\n",
        "    Args:\n",
        "        model_name (str): Name of the Ollama model (e.g., \"gemma:2b\")\n",
        "        prompt_text (str): Prompt text to send to the model\n",
        "\n",
        "    Returns:\n",
        "        str: Model response or error message\n",
        "    \"\"\"\n",
        "    try:\n",
        "        # Escape the prompt for shell\n",
        "        import shlex\n",
        "        escaped_prompt = shlex.quote(prompt_text)\n",
        "\n",
        "        # Run the Ollama command\n",
        "        result = subprocess.run(\n",
        "            f\"ollama run {model_name} {escaped_prompt}\",\n",
        "            shell=True,\n",
        "            capture_output=True,\n",
        "            text=True,\n",
        "            timeout=120  # 2 minute timeout\n",
        "        )\n",
        "\n",
        "        if result.returncode == 0:\n",
        "            return result.stdout.strip()\n",
        "        else:\n",
        "            return f\"❌ Ollama Error: {result.stderr}\"\n",
        "    except subprocess.TimeoutExpired:\n",
        "        return \"❌ Ollama subprocess timed out (2 minutes)\"\n",
        "    except Exception as e:\n",
        "        return f\"❌ Error running Ollama via subprocess: {e}\"\n",
        "\n",
        "# --- n8n Webhook Trigger Function (REAL) ---\n",
        "\n",
        "def trigger_n8n_webhook(webhook_url, payload_data):\n",
        "    \"\"\"\n",
        "    Sends data to a specified n8n webhook URL.\n",
        "\n",
        "    Args:\n",
        "        webhook_url (str): The full URL of the n8n webhook.\n",
        "        payload_data (str): A string containing the JSON payload to send.\n",
        "\n",
        "    Returns:\n",
        "        str: A status message indicating success or failure.\n",
        "    \"\"\"\n",
        "    if not webhook_url:\n",
        "        return \"❌ Error: n8n Webhook URL not provided.\"\n",
        "    if not payload_data:\n",
        "        return \"⚠️ Warning: Payload is empty.\"\n",
        "\n",
        "    headers = {'Content-Type': 'application/json'}\n",
        "    try:\n",
        "        # Validate and parse the JSON payload string\n",
        "        payload_dict = json.loads(payload_data)\n",
        "    except json.JSONDecodeError as e:\n",
        "        return f\"❌ JSON Error: Invalid JSON format in payload data. Details: {e}\"\n",
        "\n",
        "    try:\n",
        "        print(f\"ℹ️ Sending data to n8n webhook: {webhook_url}\")\n",
        "        response = requests.post(webhook_url, json=payload_dict, headers=headers, timeout=30)\n",
        "        response.raise_for_status() # Raise HTTPError for bad responses (4xx or 5xx)\n",
        "        # Try to parse n8n's response (often JSON)\n",
        "        try:\n",
        "            n8n_response = response.json()\n",
        "            return f\"✅ Successfully triggered n8n workflow.\\nResponse: {json.dumps(n8n_response, indent=2)}\"\n",
        "        except json.JSONDecodeError:\n",
        "            # If response is not JSON, return the text\n",
        "            return f\"✅ Successfully triggered n8n workflow.\\nResponse: {response.text}\"\n",
        "\n",
        "    except requests.exceptions.ConnectionError:\n",
        "        return (f\"❌ Connection Error: Could not connect to the n8n webhook URL: {webhook_url}. \"\n",
        "                f\"Ensure the URL is correct and the n8n instance/workflow is running and accessible.\")\n",
        "    except requests.exceptions.Timeout:\n",
        "        return f\"❌ Timeout Error: The request to the n8n webhook timed out.\"\n",
        "    except requests.exceptions.HTTPError as e:\n",
        "         # Handle HTTP errors (like 404 Not Found, 401 Unauthorized, 500 Internal Server Error)\n",
        "         return (f\"❌ HTTP Error: Failed to trigger n8n webhook. Status Code: {e.response.status_code}. \"\n",
        "                 f\"Response: {e.response.text}\")\n",
        "    except requests.exceptions.RequestException as e:\n",
        "        return f\"❌ Request Error: An error occurred sending data to n8n: {e}\"\n",
        "    except Exception as e:\n",
        "        return f\"❌ An unexpected error occurred triggering n8n: {e}\"\n",
        "\n",
        "\n",
        "# --- ElevenLabs Text-to-Speech Function (REAL) ---\n",
        "\n",
        "def generate_elevenlabs_audio(api_key, text_to_speak, voice_id=\"Rachel\", model_id='eleven_multilingual_v2',\n",
        "                              stability=0.7, similarity_boost=0.5):\n",
        "    \"\"\"\n",
        "    Generates audio using the real ElevenLabs API with enhanced parameters.\n",
        "\n",
        "    Args:\n",
        "        api_key (str): ElevenLabs API key.\n",
        "        text_to_speak (str): The text to convert to speech.\n",
        "        voice_id (str): The ID or name of the ElevenLabs voice to use.\n",
        "        model_id (str): The ElevenLabs model to use.\n",
        "        stability (float): Voice stability setting (0.0-1.0).\n",
        "        similarity_boost (float): Voice similarity boost setting (0.0-1.0).\n",
        "\n",
        "    Returns:\n",
        "        tuple: (filepath_or_none, status_message)\n",
        "               filepath_or_none (str | None): Path to the generated MP3 file or None on error.\n",
        "               status_message (str): A message indicating success or failure.\n",
        "    \"\"\"\n",
        "    if not api_key:\n",
        "        return None, \"❌ Error: ElevenLabs API key not provided.\"\n",
        "    if not text_to_speak:\n",
        "        return None, \"⚠️ Warning: No text provided for synthesis.\"\n",
        "\n",
        "    # Create a directory for audio output if it doesn't exist\n",
        "    output_dir = Path(\"./elevenlabs_output\")\n",
        "    output_dir.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "    try:\n",
        "        from elevenlabs.client import ElevenLabs\n",
        "        from elevenlabs import Voice, VoiceSettings, APIError\n",
        "        client = ElevenLabs(api_key=api_key)\n",
        "\n",
        "        print(f\"ℹ️ ElevenLabs: Generating audio for '{text_to_speak[:50]}...' with voice '{voice_id}'\")\n",
        "        audio_stream = client.generate(\n",
        "            text=text_to_speak,\n",
        "            voice=Voice(\n",
        "                voice_id=voice_id, # Can be voice ID or name\n",
        "                settings=VoiceSettings(stability=stability, similarity_boost=similarity_boost)\n",
        "            ),\n",
        "            model=model_id\n",
        "        )\n",
        "\n",
        "        # Save audio stream to a temporary file\n",
        "        timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
        "        output_filename = output_dir / f\"audio_{timestamp}.mp3\"\n",
        "\n",
        "        with open(output_filename, \"wb\") as f:\n",
        "            data_written = False\n",
        "            for chunk in audio_stream:\n",
        "                if chunk:\n",
        "                    f.write(chunk)\n",
        "                    data_written = True\n",
        "\n",
        "        if data_written and output_filename.exists() and output_filename.stat().st_size > 0:\n",
        "            print(f\"✅ Audio saved as {output_filename}\")\n",
        "            # Return the absolute path as a string for Gradio\n",
        "            return str(output_filename.resolve()), f\"✅ Audio generated successfully with voice '{voice_id}'.\"\n",
        "        else:\n",
        "            # Clean up empty file if created\n",
        "            if output_filename.exists():\n",
        "                output_filename.unlink()\n",
        "            return None, f\"⚠️ Warning: ElevenLabs did not return audio data for the provided text/voice.\"\n",
        "\n",
        "    except ImportError:\n",
        "         return None, \"❌ Error: 'elevenlabs' library not found. Please ensure Cell 1 ran successfully.\"\n",
        "    except APIError as e:\n",
        "         # Handle specific ElevenLabs API errors\n",
        "         if e.status_code == 401:\n",
        "             return None, f\"❌ ElevenLabs Authentication Error: Invalid API key. ({e})\"\n",
        "         elif \"quota\" in str(e).lower() or e.status_code == 402:\n",
        "              return None, f\"❌ ElevenLabs Quota Exceeded: Check your subscription limits. ({e})\"\n",
        "         else:\n",
        "             return None, f\"❌ ElevenLabs API Error: {e}\"\n",
        "    except Exception as e:\n",
        "        # Catch other unexpected errors\n",
        "        return None, f\"❌ An unexpected error occurred calling ElevenLabs: {e}\"\n",
        "\n",
        "# Local text-to-speech fallback\n",
        "def generate_local_tts(text, output_dir=\"./tts_output\"):\n",
        "    \"\"\"\n",
        "    Generate text-to-speech using local pyttsx3 library (fallback when no API key).\n",
        "\n",
        "    Args:\n",
        "        text (str): Text to convert to speech\n",
        "        output_dir (str): Directory to save the audio file\n",
        "\n",
        "    Returns:\n",
        "        tuple: (filepath_or_none, status_message)\n",
        "    \"\"\"\n",
        "    if not text:\n",
        "        return None, \"⚠️ Warning: No text provided for synthesis.\"\n",
        "\n",
        "    try:\n",
        "        # Create output directory if it doesn't exist\n",
        "        output_dir = Path(output_dir)\n",
        "        output_dir.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "        # Initialize TTS engine\n",
        "        engine = pyttsx3.init()\n",
        "\n",
        "        # Generate filename\n",
        "        timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
        "        output_file = output_dir / f\"local_tts_{timestamp}.mp3\"\n",
        "\n",
        "        # Save to file\n",
        "        engine.save_to_file(text, str(output_file))\n",
        "        engine.runAndWait()\n",
        "\n",
        "        if output_file.exists() and output_file.stat().st_size > 0:\n",
        "            return str(output_file.resolve()), \"✅ Audio generated successfully using local TTS.\"\n",
        "        else:\n",
        "            return None, \"❌ Failed to generate audio file with local TTS.\"\n",
        "\n",
        "    except Exception as e:\n",
        "        return None, f\"❌ Error with local TTS: {e}\"\n",
        "\n",
        "# --- Helper Function for Negotiation Frameworks ---\n",
        "\n",
        "def apply_negotiation_framework(framework_name, scenario_text):\n",
        "    \"\"\"\n",
        "    Creates a prompt asking an LLM to apply a specific negotiation framework.\n",
        "\n",
        "    Args:\n",
        "        framework_name (str): Name of the framework ('Island of Agreement', 'BATNA/ZOPA', etc.).\n",
        "        scenario_text (str): The negotiation scenario text.\n",
        "\n",
        "    Returns:\n",
        "        str: A formatted prompt for the LLM.\n",
        "    \"\"\"\n",
        "    if not framework_name or framework_name.lower() == 'none':\n",
        "        return scenario_text # Return original text if no framework selected\n",
        "\n",
        "    prompt_header = f\"Analyze the following humanitarian negotiation scenario using the '{framework_name}' framework:\\n\\nScenario:\\n{scenario_text}\\n\\nAnalysis ({framework_name}):\\n\"\n",
        "\n",
        "    if framework_name == 'Island of Agreement':\n",
        "        prompt_details = (\"Identify and structure the analysis into these four categories:\\n\"\n",
        "                          \"1. Contested Facts/Issues: Points of disagreement or differing information.\\n\"\n",
        "                          \"2. Agreed Facts/Issues: Points where both parties have common ground or agreement.\\n\"\n",
        "                          \"3. Divergent Norms/Values/Interests: Underlying principles or goals that differ.\\n\"\n",
        "                          \"4. Convergent Norms/Values/Interests: Shared principles or goals that can be built upon.\")\n",
        "    elif framework_name == 'BATNA/ZOPA':\n",
        "        prompt_details = (\"Identify the following for EACH key party involved (e.g., Humanitarian Org, Armed Group Alpha):\\n\"\n",
        "                          \"1. Interests: What are their underlying needs and motivations?\\n\"\n",
        "                          \"2. Options: What are possible solutions or agreements?\\n\"\n",
        "                          \"3. BATNA (Best Alternative To a Negotiated Agreement): What will they do if no agreement is reached?\\n\"\n",
        "                          \"4. ZOPA (Zone Of Possible Agreement): Is there an overlap where an agreement beneficial to both might exist? Describe it if so.\")\n",
        "    elif framework_name == 'Iceberg Analysis':\n",
        "        prompt_details = (\"For each key party in the negotiation scenario:\\n\"\n",
        "                         \"1. Position: What they say they want (visible part of iceberg)\\n\"\n",
        "                         \"2. Reasoning: Why they want it (just below surface)\\n\"\n",
        "                         \"3. Motives: Deeper needs and fears (deep underwater)\\n\\n\"\n",
        "                         \"Then provide strategic insights on finding common ground based on underlying interests.\")\n",
        "    elif framework_name == 'Stakeholder Matrix':\n",
        "        prompt_details = (\"For each stakeholder in the scenario:\\n\"\n",
        "                         \"1. Power: High/Medium/Low - Their ability to influence outcomes\\n\"\n",
        "                         \"2. Legitimacy: High/Medium/Low - Their recognized right to be involved\\n\"\n",
        "                         \"3. Urgency: High/Medium/Low - How time-sensitive their claims are\\n\"\n",
        "                         \"4. Position: Their stance on the key issues\\n\"\n",
        "                         \"5. Priority: Critical/High/Medium/Low - Overall engagement priority\\n\\n\"\n",
        "                         \"Then provide strategic insights on which stakeholders to prioritize.\")\n",
        "    elif framework_name == 'Multi-party Dynamics':\n",
        "        prompt_details = (\"Analyze the complex relationships between multiple parties:\\n\"\n",
        "                         \"1. Identify potential coalitions and their shared concerns\\n\"\n",
        "                         \"2. Map relationships between different stakeholder groups\\n\"\n",
        "                         \"3. Develop strategies for coalition-building\\n\"\n",
        "                         \"4. Identify potential spoilers and isolation strategies\")\n",
        "    elif framework_name == 'Success Factors':\n",
        "        prompt_details = (\"Identify critical elements needed for resolution:\\n\"\n",
        "                         \"1. Resolution Path: The overall approach to successful resolution\\n\"\n",
        "                         \"2. Trust-Building Actions: Steps to build confidence between parties\\n\"\n",
        "                         \"3. Stakeholder Management: How to engage different actors effectively\\n\"\n",
        "                         \"4. Process Enhancement: Improvements to negotiation structure and methodology\")\n",
        "    elif framework_name == 'Complete Crisis Framework':\n",
        "        prompt_details = (\"Create a comprehensive analysis using the Enhanced Crisis Negotiation Analyst framework with ALL of these components:\\n\"\n",
        "                          \"1. Island of Agreements: Contested facts, agreed facts, convergent norms, divergent norms\\n\"\n",
        "                          \"2. Iceberg Analysis: Underlying interests beneath stated positions for each party\\n\"\n",
        "                          \"3. Stakeholder Matrix: Map key actors by power, legitimacy, and urgency\\n\"\n",
        "                          \"4. Influence Pathways: Relationships and influence channels between stakeholders\\n\"\n",
        "                          \"5. Scenario Design: Negotiation boundaries and potential agreement zones\\n\"\n",
        "                          \"6. Multiparty Dynamics: Complex relationships and coalition opportunities\\n\"\n",
        "                          \"7. Tactical Timeline: Structured approach to resolution through phases\\n\"\n",
        "                          \"8. Radical Faction Analysis: Identify disruptive elements and management strategies\\n\"\n",
        "                          \"9. Success Factors: Critical elements for resolution\\n\\n\"\n",
        "                          \"Provide a thorough analysis covering all components with actionable recommendations.\")\n",
        "    else:\n",
        "        prompt_details = \"Provide a detailed analysis based on the principles of this framework.\" # Generic fallback\n",
        "\n",
        "    return f\"{prompt_header}\\n{prompt_details}\"\n",
        "\n",
        "# --- Helper Function for Integrated Assistant ---\n",
        "\n",
        "def build_assistant_prompt(scenario_text):\n",
        "    \"\"\"\n",
        "    Creates a structured prompt for the Integrated Assistant LLM call.\n",
        "\n",
        "    Args:\n",
        "        scenario_text (str): The negotiation scenario text.\n",
        "\n",
        "    Returns:\n",
        "        str: A formatted prompt asking for structured analysis.\n",
        "    \"\"\"\n",
        "    return f\"\"\"\n",
        "    Analyze the following humanitarian negotiation scenario comprehensively. Provide the output structured into the following sections:\n",
        "\n",
        "    **1. Executive Summary:**\n",
        "    (Provide a brief overview of the situation and key negotiation challenges/opportunities in 2-3 sentences.)\n",
        "\n",
        "    **2. Stakeholder Analysis:**\n",
        "    (Identify key stakeholders (e.g., Humanitarian Org, Armed Group Alpha, IDP Leaders, Local Authorities). For each, list:\n",
        "    * Stated Position: What they say they want.\n",
        "    * Underlying Interests: Why they want it (needs, fears, motivations).\n",
        "    * Potential Influence: How much power do they have in this situation?\n",
        "    * Possible Levers: What might influence them?)\n",
        "\n",
        "    **3. Contextual Factors:**\n",
        "    (Briefly describe relevant factors like: security situation, political climate, cultural norms, past interactions, resource availability.)\n",
        "\n",
        "    **4. Negotiation Framework Analysis (IoA & BATNA/ZOPA):**\n",
        "    * **Island of Agreement:** Briefly list key Contested Facts, Agreed Facts, Divergent Norms/Interests, Convergent Norms/Interests.\n",
        "    * **BATNA/ZOPA:** Briefly outline the likely BATNA for the main parties and assess if a ZOPA exists.\n",
        "\n",
        "    **5. Key Risks & Challenges:**\n",
        "    (List the main risks for the humanitarian organization, e.g., security, reputational, operational failure, ethical dilemmas.)\n",
        "\n",
        "    **6. Strategic Recommendations:**\n",
        "    (Provide 3-5 concrete, actionable recommendations for the negotiation team, focusing on initial steps and potential approaches. Consider sequencing, communication strategies, and potential entry points.)\n",
        "\n",
        "    **Scenario:**\n",
        "    {scenario_text}\n",
        "\n",
        "    **Analysis:**\n",
        "    \"\"\"\n",
        "\n",
        "# --- NEW: Function to build Complete Analysis Framework Prompt ---\n",
        "\n",
        "def build_crisis_analysis_prompt(scenario_text, output_format=\"text\"):\n",
        "    \"\"\"\n",
        "    Creates a structured prompt for the Crisis Negotiation Analysis Framework.\n",
        "\n",
        "    Args:\n",
        "        scenario_text (str): The crisis negotiation scenario text.\n",
        "        output_format (str): Output format - \"text\" or \"json\"\n",
        "\n",
        "    Returns:\n",
        "        str: A formatted prompt asking for structured analysis.\n",
        "    \"\"\"\n",
        "    json_instructions = \"\"\"\n",
        "    Your output must be valid JSON that precisely follows this structure:\n",
        "    {\n",
        "        \"title\": \"🏛️ [Scenario Name] Crisis Negotiation Analysis 🌉\",\n",
        "        \"subtitle\": \"💢 [Brief description of situation] 🔄\",\n",
        "        \"description\": \"📊 Strategic analysis of [scenario context] with recommendations for resolution 🧩\",\n",
        "        \"executiveSummary\": \"📝 [1-2 paragraph overview] 🔎\",\n",
        "        \"strategicApproach\": \"🎯 [Multi-track strategy explained] 📈\",\n",
        "        \"situationDescription\": \"⚠️ [Detailed situation description] 🏢\",\n",
        "        \"toolsOverview\": \"🧰 [Brief explanation of frameworks used] 📈\",\n",
        "        \"islandOfAgreements\": {\n",
        "            \"description\": \"🏝️ [Framework explanation] 🗣️\",\n",
        "            \"strategy\": \"🔍 [Strategic approach to use framework] 📚\",\n",
        "            \"contestedFacts\": [\n",
        "                \"⚖️ [Contested fact 1]\",\n",
        "                \"🛑 [Contested fact 2]\",\n",
        "                \"🔥 [Contested fact 3]\"\n",
        "            ],\n",
        "            \"agreedFacts\": [\n",
        "                \"💲 [Agreed fact 1]\",\n",
        "                \"🏠 [Agreed fact 2]\",\n",
        "                \"✊ [Agreed fact 3]\"\n",
        "            ],\n",
        "            \"convergentNorms\": [\n",
        "                \"🛡️ [Convergent norm 1]\",\n",
        "                \"❌ [Convergent norm 2]\",\n",
        "                \"🎓 [Convergent norm 3]\"\n",
        "            ],\n",
        "            \"divergentNorms\": [\n",
        "                \"⚔️ [Divergent norm 1]\",\n",
        "                \"🚫 [Divergent norm 2]\",\n",
        "                \"💰 [Divergent norm 3]\"\n",
        "            ],\n",
        "            \"factualPath\": [\n",
        "                \"📋 [Factual path element 1]\",\n",
        "                \"📝 [Factual path element 2]\"\n",
        "            ],\n",
        "            \"normativePath\": [\n",
        "                \"✅ [Normative path element 1]\",\n",
        "                \"🙏 [Normative path element 2]\"\n",
        "            ]\n",
        "        },\n",
        "        \"icebergAnalysis\": {\n",
        "            \"description\": \"❄️ [Framework explanation] 🧊\",\n",
        "            \"party1\": {\n",
        "                \"name\": \"🏛️ [Party 1 name]\",\n",
        "                \"position\": \"⛔ [Stated position]\",\n",
        "                \"reasoning\": \"🏢 [Reasoning]\",\n",
        "                \"motives\": \"🎓 [Underlying motives]\"\n",
        "            },\n",
        "            \"party2\": {\n",
        "                \"name\": \"👥 [Party 2 name]\",\n",
        "                \"position\": \"✊ [Stated position]\",\n",
        "                \"reasoning\": \"⚖️ [Reasoning]\",\n",
        "                \"motives\": \"🔑 [Underlying motives]\"\n",
        "            },\n",
        "            \"insight\": \"🔍 [Key insight from analysis] 🌉\",\n",
        "            \"strategies\": [\n",
        "                {\n",
        "                    \"title\": \"🔄 [Strategy 1 name]\",\n",
        "                    \"description\": \"🗣️ [Strategy 1 description]\"\n",
        "                },\n",
        "                {\n",
        "                    \"title\": \"🤝 [Strategy 2 name]\",\n",
        "                    \"description\": \"👂 [Strategy 2 description]\"\n",
        "                }\n",
        "            ]\n",
        "        },\n",
        "        \"stakeholderMatrix\": {\n",
        "            \"description\": \"👥 [Framework explanation] ⚖️\",\n",
        "            \"insight\": \"🎯 [Key insight from analysis] 🌉\",\n",
        "            \"stakeholders\": [\n",
        "                {\n",
        "                    \"name\": \"🏛️ [Stakeholder 1]\",\n",
        "                    \"power\": \"High\",\n",
        "                    \"legitimacy\": \"High\",\n",
        "                    \"urgency\": \"High\",\n",
        "                    \"position\": \"🎯 [Position]\",\n",
        "                    \"priority\": \"Critical\"\n",
        "                },\n",
        "                {\n",
        "                    \"name\": \"👨‍👩‍👧‍👦 [Stakeholder 2]\",\n",
        "                    \"power\": \"Medium\",\n",
        "                    \"legitimacy\": \"High\",\n",
        "                    \"urgency\": \"Medium\",\n",
        "                    \"position\": \"🎯 [Position]\",\n",
        "                    \"priority\": \"High\"\n",
        "                }\n",
        "            ]\n",
        "        },\n",
        "        \"influencePathways\": {\n",
        "            \"description\": \"🕸️ [Framework explanation] 🔀\",\n",
        "            \"strategy\": \"🎯 [Strategic approach] 📱\",\n",
        "            \"pathways\": [\n",
        "                \"🔄 [Pathway 1]\",\n",
        "                \"🤝 [Pathway 2]\"\n",
        "            ],\n",
        "            \"quadrantStrategies\": {\n",
        "                \"alliance\": [\n",
        "                    \"🔄 [Alliance strategy 1]\",\n",
        "                    \"📊 [Alliance strategy 2]\"\n",
        "                ],\n",
        "                \"coalition\": [\n",
        "                    \"🌉 [Coalition strategy 1]\",\n",
        "                    \"🤝 [Coalition strategy 2]\"\n",
        "                ],\n",
        "                \"cooperation\": [\n",
        "                    \"🙏 [Cooperation strategy 1]\",\n",
        "                    \"🛠️ [Cooperation strategy 2]\"\n",
        "                ],\n",
        "                \"mitigation\": [\n",
        "                    \"🗣️ [Mitigation strategy 1]\",\n",
        "                    \"👮 [Mitigation strategy 2]\"\n",
        "                ]\n",
        "            },\n",
        "            \"nodes\": [\n",
        "                {\n",
        "                    \"id\": \"admin\",\n",
        "                    \"label\": \"🏛️ [Node 1]\",\n",
        "                    \"type\": \"core\",\n",
        "                    \"x\": 0,\n",
        "                    \"y\": 0,\n",
        "                    \"color\": \"blue\"\n",
        "                },\n",
        "                {\n",
        "                    \"id\": \"board\",\n",
        "                    \"label\": \"👑 [Node 2]\",\n",
        "                    \"type\": \"quadrant1\",\n",
        "                    \"x\": -25,\n",
        "                    \"y\": -25,\n",
        "                    \"color\": \"purple\"\n",
        "                }\n",
        "            ],\n",
        "            \"connections\": [\n",
        "                {\n",
        "                    \"source\": \"admin\",\n",
        "                    \"target\": \"board\",\n",
        "                    \"label\": \"🔄 [Connection 1]\"\n",
        "                },\n",
        "                {\n",
        "                    \"source\": \"admin\",\n",
        "                    \"target\": \"security\",\n",
        "                    \"label\": \"👮 [Connection 2]\"\n",
        "                }\n",
        "            ]\n",
        "        },\n",
        "        \"scenarioDesign\": {\n",
        "            \"description\": \"🧩 [Framework explanation] 🎯\",\n",
        "            \"insight\": \"🔍 [Key insight] 🎯\",\n",
        "            \"party1\": {\n",
        "                \"name\": \"🏛️ [Party 1]\",\n",
        "                \"ideal\": \"⚡ [Ideal outcome]\",\n",
        "                \"bottomLine\": \"🤝 [Bottom line]\",\n",
        "                \"redLine\": \"❌ [Red line]\"\n",
        "            },\n",
        "            \"party2\": {\n",
        "                \"name\": \"👥 [Party 2]\",\n",
        "                \"ideal\": \"⚡ [Ideal outcome]\",\n",
        "                \"bottomLine\": \"🤝 [Bottom line]\",\n",
        "                \"redLine\": \"❌ [Red line]\"\n",
        "            },\n",
        "            \"areaF\": [\n",
        "                \"🏠 [Area F element 1]\",\n",
        "                \"⚖️ [Area F element 2]\"\n",
        "            ],\n",
        "            \"areaE\": [\n",
        "                \"👥 [Area E element 1]\",\n",
        "                \"🛡️ [Area E element 2]\"\n",
        "            ],\n",
        "            \"areaD\": [\n",
        "                \"🚫 [Area D element 1]\",\n",
        "                \"👥 [Area D element 2]\"\n",
        "            ],\n",
        "            \"recommendations\": [\n",
        "                \"⚙️ [Recommendation 1]\",\n",
        "                \"📅 [Recommendation 2]\"\n",
        "            ]\n",
        "        },\n",
        "        \"multipartyDynamics\": {\n",
        "            \"description\": \"👥 [Framework explanation] 🤝\",\n",
        "            \"insight\": \"🔍 [Key insight] 🌉\",\n",
        "            \"coalitions\": [\n",
        "                {\n",
        "                    \"name\": \"🏛️ [Coalition 1]\",\n",
        "                    \"concern\": \"🎯 [Main concern]\",\n",
        "                    \"members\": [\n",
        "                        \"🎓 [Member 1]\",\n",
        "                        \"👑 [Member 2]\"\n",
        "                    ]\n",
        "                },\n",
        "                {\n",
        "                    \"name\": \"✊ [Coalition 2]\",\n",
        "                    \"concern\": \"🎯 [Main concern]\",\n",
        "                    \"members\": [\n",
        "                        \"👥 [Member 1]\",\n",
        "                        \"🗣️ [Member 2]\"\n",
        "                    ]\n",
        "                }\n",
        "            ],\n",
        "            \"strategies\": [\n",
        "                {\n",
        "                    \"title\": \"🌉 [Strategy 1]\",\n",
        "                    \"description\": \"👨‍🏫 [Description]\"\n",
        "                },\n",
        "                {\n",
        "                    \"title\": \"⚔️ [Strategy 2]\",\n",
        "                    \"description\": \"🧩 [Description]\"\n",
        "                }\n",
        "            ]\n",
        "        },\n",
        "        \"tacticalTimeline\": {\n",
        "            \"description\": \"⏱️ [Framework explanation] 📅\",\n",
        "            \"currentStatus\": \"🔄 [Current situation] 🔍\",\n",
        "            \"criticalPath\": [\n",
        "                \"🛡️ [Critical path element 1]\",\n",
        "                \"🎯 [Critical path element 2]\"\n",
        "            ],\n",
        "            \"phases\": [\n",
        "                {\n",
        "                    \"title\": \"📋 [Phase 1]\",\n",
        "                    \"duration\": \"⏱️ [Duration]\",\n",
        "                    \"tasks\": [\n",
        "                        {\n",
        "                            \"text\": \"🤝 [Task 1]\",\n",
        "                            \"status\": \"pending\"\n",
        "                        },\n",
        "                        {\n",
        "                            \"text\": \"👥 [Task 2]\",\n",
        "                            \"status\": \"pending\"\n",
        "                        }\n",
        "                    ]\n",
        "                },\n",
        "                {\n",
        "                    \"title\": \"🗣️ [Phase 2]\",\n",
        "                    \"duration\": \"⏱️ [Duration]\",\n",
        "                    \"tasks\": [\n",
        "                        {\n",
        "                            \"text\": \"📝 [Task 1]\",\n",
        "                            \"status\": \"pending\"\n",
        "                        },\n",
        "                        {\n",
        "                            \"text\": \"📏 [Task 2]\",\n",
        "                            \"status\": \"pending\"\n",
        "                        }\n",
        "                    ]\n",
        "                }\n",
        "            ]\n",
        "        },\n",
        "        \"radicalFaction\": {\n",
        "            \"description\": \"🔥 [Framework explanation] ⚠️\",\n",
        "            \"insight\": \"🔍 [Key insight] 🛡️\",\n",
        "            \"characterization\": [\n",
        "                {\n",
        "                    \"label\": \"Composition 👥\",\n",
        "                    \"value\": \"📊 [Description]\"\n",
        "                },\n",
        "                {\n",
        "                    \"label\": \"Tactics 👑\",\n",
        "                    \"value\": \"🧠 [Description]\"\n",
        "                }\n",
        "            ],\n",
        "            \"managementStrategies\": [\n",
        "                {\n",
        "                    \"label\": \"Stakeholder Segmentation 🧩\",\n",
        "                    \"value\": \"⚔️ [Description]\"\n",
        "                },\n",
        "                {\n",
        "                    \"label\": \"Communication Strategy 🔍\",\n",
        "                    \"value\": \"⚖️ [Description]\"\n",
        "                }\n",
        "            ],\n",
        "            \"risks\": [\n",
        "                {\n",
        "                    \"action\": \"🔨 [Risk 1]\",\n",
        "                    \"likelihood\": \"High\",\n",
        "                    \"impact\": \"Critical\",\n",
        "                    \"mitigation\": \"🔎 [Mitigation approach]\"\n",
        "                },\n",
        "                {\n",
        "                    \"action\": \"👊 [Risk 2]\",\n",
        "                    \"likelihood\": \"Medium\",\n",
        "                    \"impact\": \"High\",\n",
        "                    \"mitigation\": \"🛡️ [Mitigation approach]\"\n",
        "                }\n",
        "            ]\n",
        "        },\n",
        "        \"successFactors\": {\n",
        "            \"description\": \"🎯 [Framework explanation] ⭐\",\n",
        "            \"resolutionPath\": \"🛣️ [Overall resolution approach] 🏆\",\n",
        "            \"factors\": [\n",
        "                {\n",
        "                    \"name\": \"🤝 [Factor 1]\",\n",
        "                    \"description\": \"⚖️ [Description]\",\n",
        "                    \"progress\": 15\n",
        "                },\n",
        "                {\n",
        "                    \"name\": \"⚙️ [Factor 2]\",\n",
        "                    \"description\": \"🧩 [Description]\",\n",
        "                    \"progress\": 10\n",
        "                }\n",
        "            ],\n",
        "            \"recommendations\": {\n",
        "                \"trustBuilding\": [\n",
        "                    \"🛠️ [Trust recommendation 1]\",\n",
        "                    \"🗣️ [Trust recommendation 2]\"\n",
        "                ],\n",
        "                \"stakeholderManagement\": [\n",
        "                    \"📝 [Stakeholder recommendation 1]\",\n",
        "                    \"👨‍🏫 [Stakeholder recommendation 2]\"\n",
        "                ],\n",
        "                \"processEnhancement\": [\n",
        "                    \"⏱️ [Process recommendation 1]\",\n",
        "                    \"📋 [Process recommendation 2]\"\n",
        "                ]\n",
        "            }\n",
        "        },\n",
        "        \"powerRelationships\": [\n",
        "            \"🏛️ [Power relationship 1]\",\n",
        "            \"👥 [Power relationship 2]\"\n",
        "        ],\n",
        "        \"islandInsight\": \"🏝️ [Island framework insight]\",\n",
        "        \"icebergInsight\": \"❄️ [Iceberg framework insight]\",\n",
        "        \"stakeholderInsight\": \"👥 [Stakeholder framework insight]\",\n",
        "        \"influenceInsight\": \"🕸️ [Influence framework insight]\",\n",
        "        \"scenarioInsight\": \"🧩 [Scenario framework insight]\",\n",
        "        \"multipartyInsight\": \"🤝 [Multiparty framework insight]\",\n",
        "        \"tacticalInsight\": \"⏱️ [Tactical framework insight]\",\n",
        "        \"radicalInsight\": \"🔥 [Radical framework insight]\",\n",
        "        \"successInsight\": \"🎯 [Success framework insight]\"\n",
        "    }\n",
        "    \"\"\"\n",
        "\n",
        "    base_prompt = \"\"\"\n",
        "    You are a Crisis Negotiation Analyst specialized in producing thorough analytical breakdowns of complex humanitarian negotiation scenarios.\n",
        "\n",
        "    Analyze the following scenario comprehensively using all 9 specialized analytical frameworks:\n",
        "\n",
        "    1. Island of Agreements (IoA) Framework - Identify starting points for dialogue\n",
        "    2. Iceberg Analysis - Reveal underlying interests beneath stated positions\n",
        "    3. Stakeholder Matrix - Map key actors based on power, legitimacy, and urgency\n",
        "    4. Influence Pathways - Visualize key relationships and influence channels\n",
        "    5. Scenario Design - Map negotiation position boundaries and identify potential agreement zones\n",
        "    6. Multiparty Dynamics - Map complex stakeholder relationships and coalition-building opportunities\n",
        "    7. Tactical Timeline - Structured approach to resolution through sequential phases\n",
        "    8. Radical Faction Analysis - Identify potentially disruptive elements and risk management strategies\n",
        "    9. Success Factors - Define critical elements needed for resolution\n",
        "\n",
        "    For each framework, provide detailed analysis with specific recommendations.\n",
        "\n",
        "    Scenario:\n",
        "    {scenario}\n",
        "    \"\"\"\n",
        "\n",
        "    if output_format == \"json\":\n",
        "        return base_prompt.format(scenario=scenario_text) + \"\\n\\n\" + json_instructions\n",
        "    else:\n",
        "        return base_prompt.format(scenario=scenario_text)\n",
        "\n",
        "# --- NEW: Function to handle MTPs (Mini Task Processes) ---\n",
        "\n",
        "def load_mtps_from_json(filepath=\"mtp_examples.json\"):\n",
        "    \"\"\"\n",
        "    Load Mini Task Processes from a JSON file.\n",
        "\n",
        "    Args:\n",
        "        filepath (str): Path to JSON file\n",
        "\n",
        "    Returns:\n",
        "        list: List of MTP dictionaries or empty list on error\n",
        "    \"\"\"\n",
        "    try:\n",
        "        with open(filepath, 'r') as f:\n",
        "            mtps = json.load(f)\n",
        "        return mtps\n",
        "    except FileNotFoundError:\n",
        "        print(f\"❌ MTP file not found: {filepath}\")\n",
        "        # Create default MTPs if file not found\n",
        "        return create_default_mtps()\n",
        "    except json.JSONDecodeError:\n",
        "        print(f\"❌ Invalid JSON in MTP file: {filepath}\")\n",
        "        return create_default_mtps()\n",
        "    except Exception as e:\n",
        "        print(f\"❌ Error loading MTPs: {e}\")\n",
        "        return create_default_mtps()\n",
        "\n",
        "def create_default_mtps():\n",
        "    \"\"\"\n",
        "    Create default MTPs for first-time use.\n",
        "\n",
        "    Returns:\n",
        "        list: List of default MTP dictionaries\n",
        "    \"\"\"\n",
        "    default_mtps = [\n",
        "        {\n",
        "            \"title\": \"Island of Agreement Analysis\",\n",
        "            \"description\": \"Identifies potential starting points for dialogue by mapping areas of convergence and divergence\",\n",
        "            \"prompt_template\": \"Analyze the following humanitarian negotiation scenario using the Island of Agreement framework: {input}\\n\\nIdentify and categorize:\\n1. Contested Facts/Issues\\n2. Agreed Facts/Issues\\n3. Divergent Norms/Values/Interests\\n4. Convergent Norms/Values/Interests\",\n",
        "            \"preferred_model\": \"Claude (Anthropic)\",\n",
        "            \"send_to_n8n\": False,\n",
        "            \"speak_output\": False\n",
        "        },\n",
        "        {\n",
        "            \"title\": \"Stakeholder Mapping\",\n",
        "            \"description\": \"Maps key actors based on power, legitimacy, and urgency\",\n",
        "            \"prompt_template\": \"Create a comprehensive stakeholder analysis for this humanitarian negotiation scenario: {input}\\n\\nFor each key stakeholder, identify:\\n1. Power level (High/Medium/Low)\\n2. Legitimacy (High/Medium/Low)\\n3. Urgency (High/Medium/Low)\\n4. Position on key issues\\n5. Priority for engagement (Critical/High/Medium/Low)\",\n",
        "            \"preferred_model\": \"GPT-4 (OpenAI)\",\n",
        "            \"send_to_n8n\": True,\n",
        "            \"speak_output\": False\n",
        "        },\n",
        "        {\n",
        "            \"title\": \"Critical Security Briefing\",\n",
        "            \"description\": \"Creates a concise security briefing for field staff with actionable points\",\n",
        "            \"prompt_template\": \"Create a concise security briefing for humanitarian field staff based on this scenario: {input}\\n\\nInclude:\\n1. Key security threats (ranked by severity)\\n2. Recommended precautions\\n3. Emergency protocols\\n4. Communication procedures\\n\\nFormat this as a brief, actionable document that could be read aloud in 2-3 minutes.\",\n",
        "            \"preferred_model\": \"GPT-4 (OpenAI)\",\n",
        "            \"send_to_n8n\": True,\n",
        "            \"speak_output\": True\n",
        "        },\n",
        "        {\n",
        "            \"title\": \"Tactical Timeline\",\n",
        "            \"description\": \"Develops a phased approach to negotiations with specific milestones\",\n",
        "            \"prompt_template\": \"Create a tactical timeline for resolving this humanitarian negotiation scenario: {input}\\n\\nStructure this into:\\n1. Current Status (assessment of where we are now)\\n2. Critical Path (key steps needed)\\n3. Phase 1: Initial Engagement (2-3 days)\\n4. Phase 2: Core Negotiation (4-7 days)\\n5. Phase 3: Implementation (7+ days)\\n\\nFor each phase, identify specific tasks, responsible parties, and success criteria.\",\n",
        "            \"preferred_model\": \"Claude (Anthropic)\",\n",
        "            \"send_to_n8n\": False,\n",
        "            \"speak_output\": False\n",
        "        },\n",
        "        {\n",
        "            \"title\": \"Complete Crisis Analysis\",\n",
        "            \"description\": \"Comprehensive analysis using all 9 frameworks with JSON output\",\n",
        "            \"prompt_template\": \"Perform a complete crisis negotiation analysis on this scenario, using all 9 analytical frameworks (Island of Agreement, Iceberg Analysis, Stakeholder Matrix, Influence Pathways, Scenario Design, Multiparty Dynamics, Tactical Timeline, Radical Faction Analysis, Success Factors). Format the output as JSON with each framework as a separate section: {input}\",\n",
        "            \"preferred_model\": \"Claude (Anthropic)\",\n",
        "            \"send_to_n8n\": True,\n",
        "            \"speak_output\": False\n",
        "        }\n",
        "    ]\n",
        "\n",
        "    # Try to save default MTPs for future use\n",
        "    try:\n",
        "        with open(\"mtp_examples.json\", 'w') as f:\n",
        "            json.dump(default_mtps, f, indent=2)\n",
        "        print(\"✅ Created default MTP file\")\n",
        "    except Exception as e:\n",
        "        print(f\"⚠️ Could not save default MTPs: {e}\")\n",
        "\n",
        "    return default_mtps\n",
        "\n",
        "def save_new_mtp(mtp_data, filepath=\"mtp_examples.json\"):\n",
        "    \"\"\"\n",
        "    Save a new MTP to the JSON file.\n",
        "\n",
        "    Args:\n",
        "        mtp_data (dict): New MTP to save\n",
        "        filepath (str): Path to JSON file\n",
        "\n",
        "    Returns:\n",
        "        bool: Success status\n",
        "    \"\"\"\n",
        "    try:\n",
        "        # Load existing MTPs\n",
        "        mtps = load_mtps_from_json(filepath)\n",
        "\n",
        "        # Add new MTP\n",
        "        mtps.append(mtp_data)\n",
        "\n",
        "        # Save back to file\n",
        "        with open(filepath, 'w') as f:\n",
        "            json.dump(mtps, f, indent=2)\n",
        "\n",
        "        return True\n",
        "    except Exception as e:\n",
        "        print(f\"❌ Error saving new MTP: {e}\")\n",
        "        return False\n",
        "\n",
        "print(\"✅ Utility functions and API callers defined.\")\n",
        "\n",
        "\n",
        "# @title Cell 3: Gradio Interface Implementation\n",
        "# ---\n",
        "# Defines the Gradio application structure using Blocks and Tabs.\n",
        "# Connects interface components to the utility functions from Cell 2.\n",
        "# All UI text is in English.\n",
        "# ---\n",
        "import gradio as gr\n",
        "import os\n",
        "import json\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import base64 # For embedding HTML interface assets\n",
        "import time # For timing API responses\n",
        "\n",
        "print(\"⏳ Creating Gradio interface...\")\n",
        "\n",
        "# --- Case Study Text (English) ---\n",
        "CASE_STUDY_EN = \"\"\"\n",
        "**Case Study: Negotiation for Humanitarian Access**\n",
        "\n",
        "An armed conflict in the North Province has resulted in approximately 20,000 internally displaced persons (IDPs) gathering in a makeshift camp near the town of Eastville. Armed Group Alpha controls the area surrounding the camp and has established checkpoints on all access roads. Your humanitarian organization needs to negotiate access to provide essential services including food, water, medical care, and protection services.\n",
        "\"\"\"\n",
        "\n",
        "# --- Edward University Case Study (from the JSON) ---\n",
        "EDWARD_UNIVERSITY_CASE = \"\"\"\n",
        "**Case Study: Edward University Campus Crisis**\n",
        "\n",
        "A peaceful student protest over tuition fees, housing conditions, and campus safety has escalated into an occupation of the administration building at Edward University, complicated by the arrest of a dozen students, the infiltration of external activists with extremist views, and intense media coverage politicizing the event. Different student factions are now in conflict over approach, with tensions at a breaking point as the situation devolves into confusion and violence.\n",
        "\n",
        "The university administration is seeking to end the occupation immediately and restore normal campus operations, while the student union's moderate faction wants to continue protest until concrete commitments address tuition, housing, and safety concerns. External activist groups have joined the protests and introduced divisive elements, some with extremist agendas.\n",
        "\n",
        "Local police maintain public order but face political considerations and campus jurisdiction issues. Faculty members have limited formal authority but significant potential as mediators with credibility on all sides. Media coverage is amplifying tensions by criticizing government response and politicizing events.\n",
        "\"\"\"\n",
        "\n",
        "# --- Island of Agreement Interface Code ---\n",
        "ioa_interface_html = \"\"\"\n",
        "<!DOCTYPE html>\n",
        "<html lang=\"en\">\n",
        "<head>\n",
        "    <meta charset=\"UTF-8\">\n",
        "    <meta name=\"viewport\" content=\"width=device-width, initial-scale=1.0\">\n",
        "    <title>Island of Agreement Tool</title>\n",
        "    <link href=\"https://cdn.jsdelivr.net/npm/bootstrap@5.3.0/dist/css/bootstrap.min.css\" rel=\"stylesheet\">\n",
        "    <style>\n",
        "        body { font-family: sans-serif; padding: 20px; background-color: #f8f9fa; }\n",
        "        .negotiation-framework { display: grid; grid-template-columns: repeat(auto-fit, minmax(250px, 1fr)); gap: 20px; }\n",
        "        .framework-section { background-color: white; border-radius: 8px; padding: 15px; box-shadow: 0 2px 4px rgba(0,0,0,0.1); }\n",
        "        .framework-section h5 { margin-bottom: 15px; color: #0d6efd; border-bottom: 2px solid #dee2e6; padding-bottom: 5px; }\n",
        "        .item { background-color: #e9ecef; border-radius: 4px; padding: 8px 12px; margin-bottom: 8px; cursor: pointer; transition: background-color 0.2s ease; }\n",
        "        .item:hover { background-color: #ced4da; }\n",
        "        .add-item-input { width: calc(100% - 45px); margin-right: 5px; }\n",
        "        .add-item-btn { width: 40px; }\n",
        "        #move-options { position: absolute; background-color: white; border: 1px solid #ccc; box-shadow: 0 2px 5px rgba(0,0,0,0.2); padding: 5px; display: none; z-index: 1000; }\n",
        "        #move-options button { display: block; width: 100%; text-align: left; padding: 5px 10px; border: none; background: none; }\n",
        "        #move-options button:hover { background-color: #f0f0f0; }\n",
        "        .context-section { background-color: #fff; padding: 20px; border-radius: 8px; box-shadow: 0 2px 4px rgba(0,0,0,0.1); margin-bottom: 20px; }\n",
        "        .context-section h4 { color: #6f42c1; } /* Violet color for context */\n",
        "    </style>\n",
        "</head>\n",
        "<body>\n",
        "    <div class=\"container-fluid\">\n",
        "        <div class=\"context-section\" id=\"context-section\">\n",
        "             <h4>Negotiation Context</h4>\n",
        "             <textarea id=\"context-input\" class=\"form-control\" rows=\"3\" placeholder=\"Briefly describe the negotiation context or paste relevant text...\"></textarea>\n",
        "             </div>\n",
        "\n",
        "        <div class=\"negotiation-framework\">\n",
        "            <div class=\"framework-section\" id=\"contested-facts\">\n",
        "                <h5>🔴 Contested Facts / Issues</h5>\n",
        "                <div id=\"contested-facts-items\"></div>\n",
        "                <div class=\"input-group input-group-sm mt-2\">\n",
        "                    <input type=\"text\" class=\"form-control add-item-input\" placeholder=\"Add contested fact...\">\n",
        "                    <button class=\"btn btn-outline-danger add-item-btn\" onclick=\"addItem('contested-facts', this)\">+</button>\n",
        "                </div>\n",
        "            </div>\n",
        "            <div class=\"framework-section\" id=\"agreed-facts\">\n",
        "                <h5>🟢 Agreed Facts / Issues</h5>\n",
        "                <div id=\"agreed-facts-items\"></div>\n",
        "                 <div class=\"input-group input-group-sm mt-2\">\n",
        "                    <input type=\"text\" class=\"form-control add-item-input\" placeholder=\"Add agreed fact...\">\n",
        "                    <button class=\"btn btn-outline-success add-item-btn\" onclick=\"addItem('agreed-facts', this)\">+</button>\n",
        "                </div>\n",
        "            </div>\n",
        "            <div class=\"framework-section\" id=\"divergent-norms\">\n",
        "                <h5>🟠 Divergent Norms / Interests</h5>\n",
        "                 <div id=\"divergent-norms-items\"></div>\n",
        "                 <div class=\"input-group input-group-sm mt-2\">\n",
        "                    <input type=\"text\" class=\"form-control add-item-input\" placeholder=\"Add divergent norm...\">\n",
        "                    <button class=\"btn btn-outline-warning add-item-btn\" onclick=\"addItem('divergent-norms', this)\">+</button>\n",
        "                </div>\n",
        "            </div>\n",
        "            <div class=\"framework-section\" id=\"convergent-norms\">\n",
        "                <h5>🔵 Convergent Norms / Interests</h5>\n",
        "                 <div id=\"convergent-norms-items\"></div>\n",
        "                 <div class=\"input-group input-group-sm mt-2\">\n",
        "                    <input type=\"text\" class=\"form-control add-item-input\" placeholder=\"Add convergent norm...\">\n",
        "                    <button class=\"btn btn-outline-primary add-item-btn\" onclick=\"addItem('convergent-norms', this)\">+</button>\n",
        "                </div>\n",
        "            </div>\n",
        "        </div>\n",
        "    </div>\n",
        "\n",
        "    <div id=\"move-options\"></div>\n",
        "\n",
        "    <script src=\"https://cdn.jsdelivr.net/npm/bootstrap@5.3.0/dist/js/bootstrap.bundle.min.js\"></script>\n",
        "    <script>\n",
        "        let currentItem = null;\n",
        "        const moveOptionsDiv = document.getElementById('move-options');\n",
        "        const sections = ['contested-facts', 'agreed-facts', 'divergent-norms', 'convergent-norms'];\n",
        "        const sectionTitles = {\n",
        "            'contested-facts': '🔴 Contested Facts',\n",
        "            'agreed-facts': '🟢 Agreed Facts',\n",
        "            'divergent-norms': '🟠 Divergent Norms',\n",
        "            'convergent-norms': '🔵 Convergent Norms'\n",
        "        };\n",
        "\n",
        "        function addItem(sectionId, buttonElement) {\n",
        "            const inputElement = buttonElement.previousElementSibling;\n",
        "            const text = inputElement.value.trim();\n",
        "            if (text === '') return;\n",
        "\n",
        "            const itemsContainer = document.getElementById(`${sectionId}-items`);\n",
        "            const itemDiv = document.createElement('div');\n",
        "            itemDiv.className = 'item';\n",
        "            itemDiv.textContent = text;\n",
        "            itemDiv.onclick = function() {\n",
        "                showMoveOptions(this, sectionId);\n",
        "            };\n",
        "            itemsContainer.appendChild(itemDiv);\n",
        "            inputElement.value = ''; // Clear input\n",
        "        }\n",
        "\n",
        "        function showMoveOptions(itemElement, currentSectionId) {\n",
        "            currentItem = itemElement;\n",
        "            moveOptionsDiv.innerHTML = ''; // Clear previous options\n",
        "\n",
        "            sections.forEach(sectionId => {\n",
        "                if (sectionId !== currentSectionId) {\n",
        "                    const button = document.createElement('button');\n",
        "                    button.textContent = `Move to ${sectionTitles[sectionId]}`;\n",
        "                    button.onclick = function() {\n",
        "                        moveItem(sectionId);\n",
        "                    };\n",
        "                    moveOptionsDiv.appendChild(button);\n",
        "                }\n",
        "            });\n",
        "\n",
        "            const deleteButton = document.createElement('button');\n",
        "            deleteButton.textContent = 'Delete Item';\n",
        "            deleteButton.style.color = 'red';\n",
        "            deleteButton.onclick = deleteItem;\n",
        "            moveOptionsDiv.appendChild(deleteButton);\n",
        "\n",
        "            // Position the move options div near the clicked item\n",
        "            const rect = itemElement.getBoundingClientRect();\n",
        "            // Adjust positioning relative to the iframe if needed, using window scroll offsets\n",
        "            moveOptionsDiv.style.top = `${window.scrollY + rect.bottom}px`;\n",
        "            moveOptionsDiv.style.left = `${window.scrollX + rect.left}px`;\n",
        "            moveOptionsDiv.style.display = 'block';\n",
        "\n",
        "            // Close options if clicking elsewhere\n",
        "             document.addEventListener('click', closeMoveOptionsOnClickOutside, true);\n",
        "        }\n",
        "\n",
        "         function closeMoveOptionsOnClickOutside(event) {\n",
        "            if (moveOptionsDiv.style.display === 'block' && !moveOptionsDiv.contains(event.target) && event.target !== currentItem) {\n",
        "                moveOptionsDiv.style.display = 'none';\n",
        "                document.removeEventListener('click', closeMoveOptionsOnClickOutside, true);\n",
        "            }\n",
        "        }\n",
        "\n",
        "\n",
        "        function moveItem(targetSectionId) {\n",
        "            if (!currentItem) return;\n",
        "            const targetContainer = document.getElementById(`${targetSectionId}-items`);\n",
        "            targetContainer.appendChild(currentItem); // Move the item\n",
        "            currentItem.onclick = function() { // Update the onclick handler for the new section\n",
        "                 showMoveOptions(this, targetSectionId);\n",
        "            };\n",
        "            moveOptionsDiv.style.display = 'none'; // Hide options\n",
        "            currentItem = null;\n",
        "             document.removeEventListener('click', closeMoveOptionsOnClickOutside, true);\n",
        "        }\n",
        "\n",
        "        function deleteItem() {\n",
        "            if (!currentItem) return;\n",
        "            currentItem.remove(); // Remove the item from the DOM\n",
        "            moveOptionsDiv.style.display = 'none'; // Hide options\n",
        "            currentItem = null;\n",
        "            document.removeEventListener('click', closeMoveOptionsOnClickOutside, true);\n",
        "        }\n",
        "\n",
        "        // --- Example Data Loading ---\n",
        "         function loadExampleData() {\n",
        "             // Clear existing items first\n",
        "             sections.forEach(id => { document.getElementById(`${id}-items`).innerHTML = ''; });\n",
        "\n",
        "             document.getElementById('context-input').value = \"Negotiating humanitarian access to IDP camp controlled by Armed Group Alpha. Key figure: Commander Khalid. Stated issues: Security concerns, need for notification. Underlying interests: Maintaining control, legitimacy, potential resource diversion.\";\n",
        "\n",
        "             addExampleItem('contested-facts', 'Number of armed personnel at checkpoint');\n",
        "             addExampleItem('contested-facts', 'Origin of recent security incident');\n",
        "             addExampleItem('contested-facts', 'Security situation on the access road');\n",
        "\n",
        "             addExampleItem('agreed-facts', 'Medical needs exist in the camp');\n",
        "             addExampleItem('agreed-facts', 'Local staff are from the community');\n",
        "             addExampleItem('agreed-facts', 'Approximately 20,000 IDPs present');\n",
        "\n",
        "\n",
        "             addExampleItem('divergent-norms', 'Humanitarian impartiality vs. local control');\n",
        "             addExampleItem('divergent-norms', 'Transparency vs. operational security');\n",
        "             addExampleItem('divergent-norms', 'International standards vs. local customs');\n",
        "\n",
        "\n",
        "             addExampleItem('convergent-norms', 'Protection of vulnerable civilians');\n",
        "             addExampleItem('convergent-norms', 'Respect for local community leadership');\n",
        "             addExampleItem('convergent-norms', 'Desire to avoid large-scale health crisis');\n",
        "\n",
        "         }\n",
        "\n",
        "         function addExampleItem(section, text) {\n",
        "             const itemsContainer = document.getElementById(`${section}-items`);\n",
        "             const itemDiv = document.createElement('div');\n",
        "             itemDiv.className = 'item';\n",
        "             itemDiv.textContent = text;\n",
        "             itemDiv.onclick = function() {\n",
        "                 showMoveOptions(this, section);\n",
        "             };\n",
        "             itemsContainer.appendChild(itemDiv);\n",
        "         }\n",
        "\n",
        "         // Add example data load button on window load\n",
        "         window.onload = function() {\n",
        "             const contextSection = document.getElementById('context-section');\n",
        "             const loadButton = document.createElement('button');\n",
        "             loadButton.className = 'btn btn-outline-secondary mt-3';\n",
        "             loadButton.textContent = 'Load Example Data';\n",
        "             loadButton.onclick = loadExampleData;\n",
        "             contextSection.appendChild(loadButton);\n",
        "         };\n",
        "\n",
        "    </script>\n",
        "</body>\n",
        "</html>\n",
        "\"\"\"\n",
        "\n",
        "# Integrated Assistant Dashboard HTML Structure (Simplified for Gradio embedding)\n",
        "# We will use Gradio components to build the input part,\n",
        "# and potentially Markdown/HTML for the output display structure.\n",
        "# This HTML is more for reference or if we decide to embed parts.\n",
        "assistant_dashboard_html_structure = \"\"\"\n",
        "    <div class=\"mb-3\">\n",
        "        <label for=\"scenarioInput\" class=\"form-label\">Negotiation Scenario:</label>\n",
        "        <textarea class=\"form-control\" id=\"scenarioInput\" rows=\"8\"></textarea>\n",
        "    </div>\n",
        "    <button id=\"analyzeButton\" class=\"btn btn-primary\">Analyze Scenario</button>\n",
        "    <hr>\n",
        "    <div class=\"card\">\n",
        "        <div class=\"card-header\">\n",
        "            <ul class=\"nav nav-tabs card-header-tabs\" id=\"analysis-tabs\" role=\"tablist\">\n",
        "                <li class=\"nav-item\" role=\"presentation\">\n",
        "                    <button class=\"nav-link active\" id=\"summary-tab\" data-bs-toggle=\"tab\" data-bs-target=\"#summary\" type=\"button\">Summary</button>\n",
        "                </li>\n",
        "                <li class=\"nav-item\" role=\"presentation\">\n",
        "                    <button class=\"nav-link\" id=\"stakeholders-tab\" data-bs-toggle=\"tab\" data-bs-target=\"#stakeholders\" type=\"button\">Stakeholders</button>\n",
        "                </li>\n",
        "                 <li class=\"nav-item\" role=\"presentation\">\n",
        "                    <button class=\"nav-link\" id=\"context-tab\" data-bs-toggle=\"tab\" data-bs-target=\"#context\" type=\"button\">Context</button>\n",
        "                </li>\n",
        "                 <li class=\"nav-item\" role=\"presentation\">\n",
        "                    <button class=\"nav-link\" id=\"analysis-tab\" data-bs-toggle=\"tab\" data-bs-target=\"#analysis\" type=\"button\">Framework Analysis</button>\n",
        "                </li>\n",
        "                 <li class=\"nav-item\" role=\"presentation\">\n",
        "                    <button class=\"nav-link\" id=\"risks-tab\" data-bs-toggle=\"tab\" data-bs-target=\"#risks\" type=\"button\">Risks</button>\n",
        "                </li>\n",
        "                <li class=\"nav-item\" role=\"presentation\">\n",
        "                    <button class=\"nav-link\" id=\"recommendations-tab\" data-bs-toggle=\"tab\" data-bs-target=\"#recommendations\" type=\"button\">Recommendations</button>\n",
        "                </li>\n",
        "            </ul>\n",
        "        </div>\n",
        "        <div class=\"card-body tab-content\" id=\"analysis-tabs-content\">\n",
        "            <div class=\"tab-pane fade show active\" id=\"summary\" role=\"tabpanel\"></div>\n",
        "            <div class=\"tab-pane fade\" id=\"stakeholders\" role=\"tabpanel\"></div>\n",
        "            <div class=\"tab-pane fade\" id=\"context\" role=\"tabpanel\"></div>\n",
        "            <div class=\"tab-pane fade\" id=\"analysis\" role=\"tabpanel\"></div>\n",
        "            <div class=\"tab-pane fade\" id=\"risks\" role=\"tabpanel\"></div>\n",
        "            <div class=\"tab-pane fade\" id=\"recommendations\" role=\"tabpanel\"></div>\n",
        "        </div>\n",
        "    </div>\n",
        "\"\"\"\n",
        "\n",
        "# Load MTP examples\n",
        "mtp_examples = load_mtps_from_json()\n",
        "\n",
        "# --- Gradio UI Construction ---\n",
        "with gr.Blocks(theme=gr.themes.Soft(), title=\"LLM Toolkit for Humanitarian Negotiation\") as app:\n",
        "    gr.Markdown(\"# 🌍 LLM Toolkit for Humanitarian Negotiation\")\n",
        "    gr.Markdown(\"A comprehensive, interactive toolkit exploring LLMs in humanitarian negotiation, based on the provided notebook.\")\n",
        "\n",
        "    # --- Tab: Introduction & Setup ---\n",
        "    with gr.Tab(\"👋 Introduction & Setup\"):\n",
        "        gr.Markdown(\"## Welcome to the Toolkit\")\n",
        "        gr.HTML(\"\"\"\n",
        "        <div style=\"background-color: #f5f5f5; padding: 20px; border-radius: 10px; border-left: 5px solid #3498db;\">\n",
        "          <h3 style=\"color: #555;\">A practical and interactive guide for humanitarian negotiators</h3>\n",
        "          <hr style=\"border-top: 1px solid #ddd;\">\n",
        "          <p style=\"font-size: 16px;\">This interactive application is designed for humanitarian professionals who want to explore how <b>Large Language Models (LLMs)</b> can enhance their negotiation capabilities in challenging contexts.</p>\n",
        "          <p style=\"font-size: 16px;\">Based on the 'LLM Toolkit for Humanitarian Negotiation' notebook.</p>\n",
        "        </div>\n",
        "        \"\"\")\n",
        "        gr.Markdown(\"## 🎯 Learning Objectives\")\n",
        "        gr.Markdown(\"\"\"\n",
        "        By using this toolkit, you will be able to:\n",
        "        1.  **Identify** which LLMs are best suited for different aspects of humanitarian negotiation.\n",
        "        2.  **Connect** to language models running locally (Ollama) for sensitive analysis and offline use.\n",
        "        3.  **Trigger** automation workflows (n8n) for negotiation preparation and analysis.\n",
        "        4.  **Generate** simple interfaces for negotiation-related projects using LLMs.\n",
        "        5.  **Integrate** advanced tools like voice synthesis (ElevenLabs) for field briefings.\n",
        "        6.  **Apply** this knowledge using an integrated Humanitarian Negotiation Assistant.\n",
        "        7.  **Leverage** Mini Task Processes (MTPs) for structured prompts and outputs.\n",
        "        8.  **Analyze** complex crisis scenarios using the Complete Crisis Framework.\n",
        "        \"\"\")\n",
        "        gr.Markdown(\"## 🔍 Case Studies\")\n",
        "        with gr.Accordion(\"IDP Camp Access Case\", open=True):\n",
        "            gr.Markdown(f\"> {CASE_STUDY_EN}\")\n",
        "\n",
        "        with gr.Accordion(\"Edward University Campus Crisis\", open=False):\n",
        "            gr.Markdown(f\"> {EDWARD_UNIVERSITY_CASE}\")\n",
        "\n",
        "        gr.Markdown(\"These scenarios will serve as our common thread for testing each tool and methodology.\")\n",
        "        gr.Markdown(\"---\")\n",
        "        gr.Markdown(\"### Initial Setup\")\n",
        "        gr.Markdown(\"Dependencies were installed when Cell 1 was executed. Ensure you have API keys ready for the cloud services you intend to use.\")\n",
        "        gr.Textbox(label=\"Current Date/Time\", value=datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\"), interactive=False)\n",
        "\n",
        "    # --- NEW Tab: Mini Task Processes (MTPs) ---\n",
        "    with gr.Tab(\"🧩 Mini Task Processes (MTPs)\"):\n",
        "        gr.Markdown(\"## Mini Task Processes (MTPs)\")\n",
        "        gr.Markdown(\"MTPs allow non-technical users to generate structured prompts using pre-defined templates. Select a task type, input your scenario, and choose your preferred model.\")\n",
        "\n",
        "        # MTP Selection\n",
        "        mtp_dropdown = gr.Dropdown(\n",
        "            label=\"🔍 Select Task Type\",\n",
        "            choices=[mtp[\"title\"] for mtp in mtp_examples],\n",
        "            value=mtp_examples[0][\"title\"] if mtp_examples else None\n",
        "        )\n",
        "        mtp_description = gr.Markdown(\"*Select a task to see its description*\")\n",
        "\n",
        "        # Input area\n",
        "        mtp_input = gr.Textbox(\n",
        "            label=\"📝 Enter Scenario Text\",\n",
        "            placeholder=\"Enter your scenario or case study here...\",\n",
        "            lines=6\n",
        "        )\n",
        "\n",
        "        # Load examples\n",
        "        load_case_study_btn_mtp1 = gr.Button(\"Load IDP Camp Case\")\n",
        "        load_case_study_btn_mtp2 = gr.Button(\"Load University Crisis Case\")\n",
        "\n",
        "        # API Keys\n",
        "        with gr.Accordion(\"🔑 API Keys (Required for selected models)\", open=False):\n",
        "            with gr.Row():\n",
        "                openai_key_mtp = gr.Textbox(label=\"OpenAI API Key\", type=\"password\")\n",
        "                gemini_key_mtp = gr.Textbox(label=\"Google AI API Key\", type=\"password\")\n",
        "                anthropic_key_mtp = gr.Textbox(label=\"Anthropic API Key\", type=\"password\")\n",
        "                mistral_key_mtp = gr.Textbox(label=\"Mistral AI API Key\", type=\"password\")\n",
        "                huggingface_key_mtp = gr.Textbox(label=\"Hugging Face API Key\", type=\"password\")\n",
        "\n",
        "            with gr.Row():\n",
        "                elevenlabs_key_mtp = gr.Textbox(label=\"ElevenLabs API Key\", type=\"password\")\n",
        "                ollama_url_mtp = gr.Textbox(label=\"Ollama URL\", value=\"http://localhost:11434\")\n",
        "                ollama_model_mtp = gr.Dropdown(\n",
        "                    label=\"Ollama Model\",\n",
        "                    choices=[\"gemma:2b\", \"llama3:8b\", \"mistral:7b\", \"gemma:7b\", \"phi3:mini\"],\n",
        "                    value=\"gemma:2b\"\n",
        "                )\n",
        "\n",
        "        # LLM Model Override (if user wants to use different model than recommended)\n",
        "        with gr.Accordion(\"🤖 Model Selection\", open=True):\n",
        "            mtp_recommended_model = gr.Markdown(\"*Recommended model will appear here*\")\n",
        "            override_model = gr.Checkbox(label=\"Override recommended model\", value=False)\n",
        "            with gr.Column(visible=False) as override_model_col:\n",
        "                selected_model = gr.Radio(\n",
        "                    label=\"Select Model\",\n",
        "                    choices=[\"GPT-4 (OpenAI)\", \"Gemini (Google)\", \"Claude (Anthropic)\", \"Mistral (Mistral AI)\",\n",
        "                             \"Hugging Face (Inference API)\", \"Ollama (Local)\"],\n",
        "                    value=\"Claude (Anthropic)\"\n",
        "                )\n",
        "\n",
        "        # Output options\n",
        "        with gr.Row():\n",
        "            send_to_n8n_checkbox = gr.Checkbox(label=\"📤 Send results to n8n\", value=False)\n",
        "            speak_output_checkbox = gr.Checkbox(label=\"🔊 Convert output to speech\", value=False)\n",
        "\n",
        "        with gr.Row(visible=False) as n8n_settings:\n",
        "            n8n_webhook_url_mtp = gr.Textbox(label=\"🔗 n8n Webhook URL\", placeholder=\"Enter your n8n webhook URL\")\n",
        "\n",
        "        with gr.Row(visible=False) as voice_settings:\n",
        "            voice_id_mtp = gr.Dropdown(\n",
        "                label=\"🎙️ Voice\",\n",
        "                choices=[\"Rachel\", \"Adam\", \"Antoni\", \"Arnold\", \"Bella\", \"Domi\", \"Elli\", \"Josh\", \"Nicole\", \"Sarah\"],\n",
        "                value=\"Rachel\"\n",
        "            )\n",
        "\n",
        "        # Processing button\n",
        "        process_mtp_button = gr.Button(\"📋 Process Task\", variant=\"primary\")\n",
        "\n",
        "        # Output areas\n",
        "        mtp_output_text = gr.Textbox(label=\"Task Output\", lines=12)\n",
        "        mtp_audio_output = gr.Audio(label=\"Audio Output\", type=\"filepath\", visible=False)\n",
        "        mtp_output_status = gr.Textbox(label=\"Status\", lines=2)\n",
        "\n",
        "        # --- MTP Logic ---\n",
        "\n",
        "        # Display MTP description when selected\n",
        "        def update_mtp_description(selected_mtp):\n",
        "            for mtp in mtp_examples:\n",
        "                if mtp[\"title\"] == selected_mtp:\n",
        "                    return f\"**Description:** {mtp['description']}\"\n",
        "            return \"*No description available*\"\n",
        "\n",
        "        def update_recommended_model(selected_mtp):\n",
        "            for mtp in mtp_examples:\n",
        "                if mtp[\"title\"] == selected_mtp:\n",
        "                    return f\"**Recommended Model:** {mtp['preferred_model']}\"\n",
        "            return \"*No model recommendation available*\"\n",
        "\n",
        "        def update_output_settings(selected_mtp):\n",
        "            for mtp in mtp_examples:\n",
        "                if mtp[\"title\"] == selected_mtp:\n",
        "                    send_to_n8n = mtp.get(\"send_to_n8n\", False)\n",
        "                    speak_output = mtp.get(\"speak_output\", False)\n",
        "                    return send_to_n8n, speak_output\n",
        "            return False, False\n",
        "\n",
        "        # Process MTP button logic\n",
        "        def process_mtp(selected_mtp, input_text, openai_key, gemini_key, anthropic_key, mistral_key,\n",
        "                        huggingface_key, elevenlabs_key, ollama_url, ollama_model, override_model_option,\n",
        "                        selected_model_override, send_to_n8n, n8n_url, speak_output, voice_id):\n",
        "\n",
        "            if not input_text:\n",
        "                return \"Please enter a scenario text.\", None, \"⚠️ Error: No input provided.\"\n",
        "\n",
        "            # Get MTP template\n",
        "            template = \"\"\n",
        "            preferred_model = \"\"\n",
        "            for mtp in mtp_examples:\n",
        "                if mtp[\"title\"] == selected_mtp:\n",
        "                    template = mtp.get(\"prompt_template\", \"\")\n",
        "                    preferred_model = mtp.get(\"preferred_model\", \"Claude (Anthropic)\")\n",
        "                    break\n",
        "\n",
        "            if not template:\n",
        "                return \"Error: Could not find template for selected task.\", None, \"⚠️ Error: Template not found.\"\n",
        "\n",
        "            # Apply template\n",
        "            prompt = template.replace(\"{input}\", input_text)\n",
        "\n",
        "            # Determine which model to use\n",
        "            model_to_use = selected_model_override if override_model_option else preferred_model\n",
        "\n",
        "            # Process with selected model\n",
        "            start_time = time.time()\n",
        "            result = \"ERROR: Model processing failed.\"\n",
        "\n",
        "            try:\n",
        "                if model_to_use == \"GPT-4 (OpenAI)\":\n",
        "                    if not openai_key:\n",
        "                        return \"ERROR: OpenAI API key required for this task.\", None, \"⚠️ Error: No OpenAI API key provided.\"\n",
        "                    result = call_openai_api(openai_key, prompt)\n",
        "\n",
        "                elif model_to_use == \"Gemini (Google)\":\n",
        "                    if not gemini_key:\n",
        "                        return \"ERROR: Google AI API key required for this task.\", None, \"⚠️ Error: No Google AI API key provided.\"\n",
        "                    result = call_gemini_api(gemini_key, prompt)\n",
        "\n",
        "                elif model_to_use == \"Claude (Anthropic)\":\n",
        "                    if not anthropic_key:\n",
        "                        return \"ERROR: Anthropic API key required for this task.\", None, \"⚠️ Error: No Anthropic API key provided.\"\n",
        "                    result = call_claude_api(anthropic_key, prompt)\n",
        "\n",
        "                elif model_to_use == \"Mistral (Mistral AI)\":\n",
        "                    if not mistral_key:\n",
        "                        return \"ERROR: Mistral AI API key required for this task.\", None, \"⚠️ Error: No Mistral AI API key provided.\"\n",
        "                    result = call_mistral_api(mistral_key, prompt)\n",
        "\n",
        "                elif model_to_use == \"Hugging Face (Inference API)\":\n",
        "                    if not huggingface_key:\n",
        "                        return \"ERROR: Hugging Face API key required for this task.\", None, \"⚠️ Error: No Hugging Face API key provided.\"\n",
        "                    result = call_huggingface_api(huggingface_key, prompt)\n",
        "\n",
        "                elif model_to_use == \"Ollama (Local)\":\n",
        "                    result = call_ollama_api(ollama_model, prompt, ollama_url)\n",
        "\n",
        "                else:\n",
        "                    return f\"ERROR: Unknown model type {model_to_use}\", None, f\"⚠️ Error: Unknown model {model_to_use}\"\n",
        "\n",
        "            except Exception as e:\n",
        "                return f\"ERROR: {str(e)}\", None, f\"⚠️ Error processing task: {str(e)}\"\n",
        "\n",
        "            processing_time = time.time() - start_time\n",
        "            status = f\"✅ Task processed in {processing_time:.2f} seconds using {model_to_use}\"\n",
        "\n",
        "            # Handle n8n if requested\n",
        "            if send_to_n8n and n8n_url:\n",
        "                try:\n",
        "                    n8n_payload = json.dumps({\n",
        "                        \"task_type\": selected_mtp,\n",
        "                        \"input\": input_text,\n",
        "                        \"output\": result,\n",
        "                        \"model\": model_to_use,\n",
        "                        \"timestamp\": datetime.now().isoformat()\n",
        "                    })\n",
        "\n",
        "                    n8n_response = trigger_n8n_webhook(n8n_url, n8n_payload)\n",
        "                    status += f\"\\n{n8n_response}\"\n",
        "                except Exception as e:\n",
        "                    status += f\"\\n❌ n8n Error: {str(e)}\"\n",
        "\n",
        "            # Handle voice synthesis if requested\n",
        "            audio_path = None\n",
        "            if speak_output:\n",
        "                try:\n",
        "                    if elevenlabs_key:\n",
        "                        audio_path, voice_status = generate_elevenlabs_audio(elevenlabs_key, result, voice_id)\n",
        "                        status += f\"\\n{voice_status}\"\n",
        "                    else:\n",
        "                        # Fallback to local TTS\n",
        "                        audio_path, voice_status = generate_local_tts(result)\n",
        "                        status += f\"\\n{voice_status} (using local TTS)\"\n",
        "                except Exception as e:\n",
        "                    status += f\"\\n❌ Voice synthesis error: {str(e)}\"\n",
        "\n",
        "            # Return results\n",
        "            return result, audio_path, status\n",
        "\n",
        "        # Connect UI components\n",
        "        mtp_dropdown.change(\n",
        "            fn=update_mtp_description,\n",
        "            inputs=mtp_dropdown,\n",
        "            outputs=mtp_description\n",
        "        )\n",
        "\n",
        "        mtp_dropdown.change(\n",
        "            fn=update_recommended_model,\n",
        "            inputs=mtp_dropdown,\n",
        "            outputs=mtp_recommended_model\n",
        "        )\n",
        "\n",
        "        mtp_dropdown.change(\n",
        "            fn=update_output_settings,\n",
        "            inputs=mtp_dropdown,\n",
        "            outputs=[send_to_n8n_checkbox, speak_output_checkbox]\n",
        "        )\n",
        "\n",
        "        override_model.change(\n",
        "            fn=lambda x: gr.update(visible=x),\n",
        "            inputs=override_model,\n",
        "            outputs=override_model_col\n",
        "        )\n",
        "\n",
        "        send_to_n8n_checkbox.change(\n",
        "            fn=lambda x: gr.update(visible=x),\n",
        "            inputs=send_to_n8n_checkbox,\n",
        "            outputs=n8n_settings\n",
        "        )\n",
        "\n",
        "        speak_output_checkbox.change(\n",
        "            fn=lambda x: gr.update(visible=x),\n",
        "            inputs=speak_output_checkbox,\n",
        "            outputs=voice_settings\n",
        "        )\n",
        "\n",
        "        speak_output_checkbox.change(\n",
        "            fn=lambda x: gr.update(visible=x),\n",
        "            inputs=speak_output_checkbox,\n",
        "            outputs=mtp_audio_output\n",
        "        )\n",
        "\n",
        "        load_case_study_btn_mtp1.click(lambda: CASE_STUDY_EN, inputs=[], outputs=mtp_input)\n",
        "        load_case_study_btn_mtp2.click(lambda: EDWARD_UNIVERSITY_CASE, inputs=[], outputs=mtp_input)\n",
        "\n",
        "        process_mtp_button.click(\n",
        "            fn=process_mtp,\n",
        "            inputs=[\n",
        "                mtp_dropdown, mtp_input,\n",
        "                openai_key_mtp, gemini_key_mtp, anthropic_key_mtp, mistral_key_mtp, huggingface_key_mtp,\n",
        "                elevenlabs_key_mtp, ollama_url_mtp, ollama_model_mtp,\n",
        "                override_model, selected_model,\n",
        "                send_to_n8n_checkbox, n8n_webhook_url_mtp,\n",
        "                speak_output_checkbox, voice_id_mtp\n",
        "            ],\n",
        "            outputs=[mtp_output_text, mtp_audio_output, mtp_output_status]\n",
        "        )\n",
        "\n",
        "        # Create new MTP section\n",
        "        with gr.Accordion(\"➕ Create New Task Template\", open=False):\n",
        "            gr.Markdown(\"Create a new Mini Task Process (MTP) template for future use.\")\n",
        "\n",
        "            new_mtp_title = gr.Textbox(label=\"Title\", placeholder=\"Enter a descriptive title for this task\")\n",
        "            new_mtp_description = gr.Textbox(label=\"Description\", placeholder=\"Enter a brief description of what this task does\")\n",
        "            new_mtp_template = gr.Textbox(\n",
        "                label=\"Prompt Template\",\n",
        "                placeholder=\"Enter the prompt template with {input} where the scenario text should go\",\n",
        "                lines=6\n",
        "            )\n",
        "            new_mtp_model = gr.Dropdown(\n",
        "                label=\"Preferred Model\",\n",
        "                choices=[\"GPT-4 (OpenAI)\", \"Gemini (Google)\", \"Claude (Anthropic)\", \"Mistral (Mistral AI)\",\n",
        "                         \"Hugging Face (Inference API)\", \"Ollama (Local)\"],\n",
        "                value=\"Claude (Anthropic)\"\n",
        "            )\n",
        "            new_mtp_n8n = gr.Checkbox(label=\"Send to n8n by default\", value=False)\n",
        "            new_mtp_voice = gr.Checkbox(label=\"Generate voice by default\", value=False)\n",
        "\n",
        "            save_new_mtp_button = gr.Button(\"💾 Save New Task Template\")\n",
        "            new_mtp_status = gr.Textbox(label=\"Status\", interactive=False)\n",
        "\n",
        "            def save_mtp_template(title, description, template, model, n8n, voice):\n",
        "                if not title or not template:\n",
        "                    return \"⚠️ Error: Title and template are required.\"\n",
        "\n",
        "                new_mtp = {\n",
        "                    \"title\": title,\n",
        "                    \"description\": description,\n",
        "                    \"prompt_template\": template,\n",
        "                    \"preferred_model\": model,\n",
        "                    \"send_to_n8n\": n8n,\n",
        "                    \"speak_output\": voice\n",
        "                }\n",
        "\n",
        "                success = save_new_mtp(new_mtp)\n",
        "\n",
        "                if success:\n",
        "                    # Reload MTP examples\n",
        "                    global mtp_examples\n",
        "                    mtp_examples = load_mtps_from_json()\n",
        "                    return f\"✅ Successfully saved new task template: {title}\"\n",
        "                else:\n",
        "                    return \"❌ Error saving template. Check console for details.\"\n",
        "\n",
        "            save_new_mtp_button.click(\n",
        "                fn=save_mtp_template,\n",
        "                inputs=[new_mtp_title, new_mtp_description, new_mtp_template,\n",
        "                        new_mtp_model, new_mtp_n8n, new_mtp_voice],\n",
        "                outputs=new_mtp_status\n",
        "            )\n",
        "\n",
        "    # --- NEW Tab: Crisis Negotiation Analysis Framework ---\n",
        "    with gr.Tab(\"🔎 Crisis Analysis Framework\"):\n",
        "        gr.Markdown(\"## Crisis Negotiation Analysis Framework\")\n",
        "        gr.Markdown(\"\"\"\n",
        "        This comprehensive framework integrates 9 specialized analytical approaches to assess complex crisis negotiations:\n",
        "\n",
        "        1. **Island of Agreements (IoA)** - Identify starting points for dialogue by mapping convergence/divergence\n",
        "        2. **Iceberg Analysis** - Reveal underlying interests beneath stated positions\n",
        "        3. **Stakeholder Matrix** - Map key actors based on power, legitimacy, and urgency\n",
        "        4. **Influence Pathways** - Visualize key relationships and influence channels\n",
        "        5. **Scenario Design** - Map negotiation position boundaries and identify potential agreement zones\n",
        "        6. **Multiparty Dynamics** - Map complex stakeholder relationships and coalition-building opportunities\n",
        "        7. **Tactical Timeline** - Structured approach to resolution through sequential phases\n",
        "        8. **Radical Faction Analysis** - Identify potentially disruptive elements and risk management strategies\n",
        "        9. **Success Factors** - Define critical elements needed for resolution\n",
        "        \"\"\")\n",
        "\n",
        "        # Input section\n",
        "        crisis_scenario_input = gr.Textbox(\n",
        "            label=\"📝 Enter Crisis Scenario\",\n",
        "            placeholder=\"Describe the crisis scenario in detail...\",\n",
        "            lines=8\n",
        "        )\n",
        "\n",
        "        # Load example buttons\n",
        "        with gr.Row():\n",
        "            load_case_study_btn_crisis1 = gr.Button(\"Load IDP Camp Case\")\n",
        "            load_case_study_btn_crisis2 = gr.Button(\"Load University Crisis Case\")\n",
        "\n",
        "        # API Keys\n",
        "        with gr.Accordion(\"🔑 API Keys\", open=False):\n",
        "            with gr.Row():\n",
        "                openai_key_crisis = gr.Textbox(label=\"OpenAI API Key\", type=\"password\")\n",
        "                claude_key_crisis = gr.Textbox(label=\"Claude API Key\", type=\"password\")\n",
        "\n",
        "        # Output format selection\n",
        "        output_format = gr.Radio(\n",
        "            label=\"Select Output Format\",\n",
        "            choices=[\"Text Analysis\", \"JSON Structured Output\"],\n",
        "            value=\"Text Analysis\"\n",
        "        )\n",
        "\n",
        "        # Model selection\n",
        "        model_choice_crisis = gr.Dropdown(\n",
        "            label=\"Select LLM\",\n",
        "            choices=[\"GPT-4 (OpenAI)\", \"Claude (Anthropic)\"],\n",
        "            value=\"Claude (Anthropic)\",\n",
        "            info=\"We recommend Claude or GPT-4 for this complex analysis task.\"\n",
        "        )\n",
        "\n",
        "        # Analysis button\n",
        "        analyze_crisis_button = gr.Button(\"🧠 Generate Comprehensive Analysis\", variant=\"primary\")\n",
        "\n",
        "        # Results\n",
        "        crisis_analysis_output = gr.Markdown(\"*Analysis results will appear here*\")\n",
        "\n",
        "        # Optional: JSON view for structured output\n",
        "        with gr.Accordion(\"View/Copy JSON Output\", open=False):\n",
        "            json_output = gr.Code(\n",
        "                label=\"JSON Output\",\n",
        "                language=\"json\",\n",
        "                interactive=True,\n",
        "                lines=10\n",
        "            )\n",
        "\n",
        "        # Crisis Analysis Logic\n",
        "        def perform_crisis_analysis(scenario, output_format, model_choice, openai_key, claude_key):\n",
        "            if not scenario:\n",
        "                return \"⚠️ Please enter a crisis scenario to analyze.\", \"{}\"\n",
        "\n",
        "            # Build prompt based on output format\n",
        "            prompt = build_crisis_analysis_prompt(scenario, output_format.lower().split()[0])\n",
        "\n",
        "            # Select model and perform analysis\n",
        "            result = \"Error performing analysis.\"\n",
        "\n",
        "            if model_choice == \"GPT-4 (OpenAI)\":\n",
        "                if not openai_key:\n",
        "                    return \"❌ Error: OpenAI API key required for this analysis.\", \"{}\"\n",
        "\n",
        "                system_message = \"You are a Crisis Negotiation Analyst specialized in comprehensive analytical breakdowns of complex humanitarian negotiation scenarios.\"\n",
        "                result = call_openai_api(openai_key, prompt, model=\"gpt-4-turbo\", system_message=system_message)\n",
        "\n",
        "            elif model_choice == \"Claude (Anthropic)\":\n",
        "                if not claude_key:\n",
        "                    return \"❌ Error: Claude API key required for this analysis.\", \"{}\"\n",
        "\n",
        "                system_message = \"You are a Crisis Negotiation Analyst specialized in comprehensive analytical breakdowns of complex humanitarian negotiation scenarios.\"\n",
        "                result = call_claude_api(claude_key, prompt, model=\"claude-3-sonnet-20240229\", system_message=system_message)\n",
        "\n",
        "            # Extract JSON if needed\n",
        "            json_content = \"{}\"\n",
        "            if output_format == \"JSON Structured Output\":\n",
        "                try:\n",
        "                    # Try to find and extract JSON from the result\n",
        "                    json_start = result.find(\"{\")\n",
        "                    json_end = result.rfind(\"}\")\n",
        "\n",
        "                    if json_start >= 0 and json_end >= 0:\n",
        "                        json_str = result[json_start:json_end+1]\n",
        "                        # Validate JSON by parsing it\n",
        "                        json_obj = json.loads(json_str)\n",
        "                        # Format it nicely\n",
        "                        json_content = json.dumps(json_obj, indent=2)\n",
        "                    else:\n",
        "                        json_content = '{\"error\": \"No valid JSON found in response\"}'\n",
        "                except Exception as e:\n",
        "                    json_content = f'{{\"error\": \"Failed to parse JSON: {str(e)}\"}}'\n",
        "\n",
        "            return result, json_content\n",
        "\n",
        "        # Connect UI components\n",
        "        load_case_study_btn_crisis1.click(lambda: CASE_STUDY_EN, inputs=[], outputs=crisis_scenario_input)\n",
        "        load_case_study_btn_crisis2.click(lambda: EDWARD_UNIVERSITY_CASE, inputs=[], outputs=crisis_scenario_input)\n",
        "\n",
        "        analyze_crisis_button.click(\n",
        "            fn=perform_crisis_analysis,\n",
        "            inputs=[crisis_scenario_input, output_format, model_choice_crisis, openai_key_crisis, claude_key_crisis],\n",
        "            outputs=[crisis_analysis_output, json_output]\n",
        "        )\n",
        "\n",
        "        # Show relevant sections of structured output\n",
        "        output_format.change(\n",
        "            fn=lambda x: gr.update(visible=(x == \"JSON Structured Output\")),\n",
        "            inputs=output_format,\n",
        "            outputs=json_output.parent\n",
        "        )\n",
        "\n",
        "    # --- Tab: LLM Platform Comparison ---\n",
        "    with gr.Tab(\"🔄 LLM Platform Comparison\"):\n",
        "        gr.Markdown(\"## Compare Multiple LLM Platforms Side-by-Side\")\n",
        "        gr.Markdown(\"This tab allows you to directly compare responses from different LLM platforms on the same humanitarian negotiation prompt, helping you identify which platform is best suited for specific tasks.\")\n",
        "\n",
        "        # API Keys Section for all platforms\n",
        "        with gr.Row():\n",
        "            openai_key_comp = gr.Textbox(label=\"🔑 OpenAI API Key\", type=\"password\", placeholder=\"Enter your OpenAI API key (sk-...)\")\n",
        "            gemini_key_comp = gr.Textbox(label=\"🔑 Google AI (Gemini) API Key\", type=\"password\", placeholder=\"Enter your Google AI API key\")\n",
        "            claude_key_comp = gr.Textbox(label=\"🔑 Anthropic (Claude) API Key\", type=\"password\", placeholder=\"Enter your Anthropic API key\")\n",
        "            mistral_key_comp = gr.Textbox(label=\"🔑 Mistral AI API Key\", type=\"password\", placeholder=\"Enter your Mistral AI key\")\n",
        "\n",
        "        # Ollama settings (if needed for comparison)\n",
        "        with gr.Row():\n",
        "            ollama_url_comp = gr.Textbox(label=\"Ollama API URL (Local)\", value=\"http://localhost:11434\", placeholder=\"Usually http://localhost:11434\")\n",
        "            ollama_model_comp = gr.Dropdown(\n",
        "                label=\"Ollama Model (Local)\",\n",
        "                choices=[\"llama3:8b\", \"mistral:7b\", \"gemma:7b\", \"phi3:mini\"],\n",
        "                value=\"llama3:8b\",\n",
        "                allow_custom_value=True\n",
        "            )\n",
        "\n",
        "        # Prompt and LLM Selection\n",
        "        gr.Markdown(\"### Prompt & Models to Compare\")\n",
        "        prompt_input_comp = gr.Textbox(label=\"📝 Enter Prompt for Comparison\", lines=7, placeholder=\"Enter your prompt here...\")\n",
        "        with gr.Row():\n",
        "            load_case_study_btn_comp1 = gr.Button(\"Load IDP Camp Case\")\n",
        "            load_case_study_btn_comp2 = gr.Button(\"Load University Crisis Case\")\n",
        "\n",
        "        # Model selection (checkboxes so users can select multiple)\n",
        "        gr.Markdown(\"### Select Models to Compare\")\n",
        "        with gr.Row():\n",
        "            use_openai_check = gr.Checkbox(label=\"OpenAI (ChatGPT)\", value=True)\n",
        "            use_gemini_check = gr.Checkbox(label=\"Google (Gemini)\", value=True)\n",
        "            use_claude_check = gr.Checkbox(label=\"Anthropic (Claude)\", value=True)\n",
        "            use_mistral_check = gr.Checkbox(label=\"Mistral AI\", value=False)\n",
        "            use_ollama_check = gr.Checkbox(label=\"Ollama (Local)\", value=False)\n",
        "\n",
        "        # Optional framework application\n",
        "        framework_choice_comp = gr.Dropdown(\n",
        "            label=\"Apply Negotiation Framework to Prompt (Optional)\",\n",
        "            choices=[\"None\", \"Island of Agreement\", \"BATNA/ZOPA\", \"Iceberg Analysis\", \"Stakeholder Matrix\", \"Multi-party Dynamics\", \"Success Factors\"],\n",
        "            value=\"None\"\n",
        "        )\n",
        "\n",
        "        # Run comparison button\n",
        "        compare_button = gr.Button(\"🔍 Run Comparison\", variant=\"primary\")\n",
        "\n",
        "        # Results display (using a DataFrame for side-by-side view)\n",
        "        gr.Markdown(\"### Comparison Results\")\n",
        "        comparison_results = gr.Dataframe(\n",
        "            headers=[\"Model\", \"Response\", \"Response Time (s)\"],\n",
        "            datatype=[\"str\", \"str\", \"number\"],\n",
        "            row_count=(5, \"fixed\"),\n",
        "            col_count=(3, \"fixed\"),\n",
        "            interactive=False,\n",
        "        )\n",
        "\n",
        "        # Detailed Response View (for when results table is too condensed)\n",
        "        with gr.Accordion(\"Detailed Response View\", open=False):\n",
        "            selected_model_detail = gr.Dropdown(label=\"Select Model for Detailed View\", choices=[\"OpenAI (ChatGPT)\", \"Google (Gemini)\", \"Anthropic (Claude)\", \"Mistral AI\", \"Ollama (Local)\"])\n",
        "            detailed_response = gr.Textbox(label=\"Detailed Response\", lines=15, interactive=False)\n",
        "\n",
        "        # Performance metrics visualization\n",
        "        with gr.Accordion(\"Performance Metrics\", open=False):\n",
        "            metrics_html = gr.HTML(\"\"\"\n",
        "            <div id=\"metrics-placeholder\">\n",
        "                <p>Run a comparison to see performance metrics.</p>\n",
        "                <p>Metrics will show response times and other data about the model responses.</p>\n",
        "            </div>\n",
        "            \"\"\")\n",
        "\n",
        "        # --- Comparison Logic ---\n",
        "        def run_llm_comparison(openai_key, gemini_key, claude_key, mistral_key,\n",
        "                              ollama_url, ollama_model, prompt_text,\n",
        "                              use_openai, use_gemini, use_claude, use_mistral, use_ollama,\n",
        "                              framework):\n",
        "\n",
        "            if not prompt_text:\n",
        "                return ([[\"❌ Error\", \"Please enter a prompt to compare responses.\", 0]],\n",
        "                        [], \"No comparison run yet.\")\n",
        "\n",
        "            # Apply framework to the prompt if selected\n",
        "            processed_prompt = apply_negotiation_framework(framework, prompt_text)\n",
        "\n",
        "            results = []\n",
        "            responses = {}  # To store detailed responses for the dropdown view\n",
        "\n",
        "            # OpenAI\n",
        "            if use_openai:\n",
        "                if not openai_key:\n",
        "                    results.append([\"OpenAI (ChatGPT)\", \"❌ Error: API key not provided\", 0])\n",
        "                    responses[\"OpenAI (ChatGPT)\"] = \"❌ Error: API key not provided\"\n",
        "                else:\n",
        "                    start_time = time.time()\n",
        "                    response = call_openai_api(openai_key, processed_prompt)\n",
        "                    elapsed = time.time() - start_time\n",
        "\n",
        "                    # Truncate response for the table display if too long\n",
        "                    table_response = response[:500] + \"...\" if len(response) > 500 else response\n",
        "                    results.append([\"OpenAI (ChatGPT)\", table_response, round(elapsed, 2)])\n",
        "                    responses[\"OpenAI (ChatGPT)\"] = response\n",
        "\n",
        "            # Gemini\n",
        "            if use_gemini:\n",
        "                if not gemini_key:\n",
        "                    results.append([\"Google (Gemini)\", \"❌ Error: API key not provided\", 0])\n",
        "                    responses[\"Google (Gemini)\"] = \"❌ Error: API key not provided\"\n",
        "                else:\n",
        "                    start_time = time.time()\n",
        "                    response = call_gemini_api(gemini_key, processed_prompt)\n",
        "                    elapsed = time.time() - start_time\n",
        "\n",
        "                    table_response = response[:500] + \"...\" if len(response) > 500 else response\n",
        "                    results.append([\"Google (Gemini)\", table_response, round(elapsed, 2)])\n",
        "                    responses[\"Google (Gemini)\"] = response\n",
        "\n",
        "            # Claude\n",
        "            if use_claude:\n",
        "                if not claude_key:\n",
        "                    results.append([\"Anthropic (Claude)\", \"❌ Error: API key not provided\", 0])\n",
        "                    responses[\"Anthropic (Claude)\"] = \"❌ Error: API key not provided\"\n",
        "                else:\n",
        "                    start_time = time.time()\n",
        "                    response = call_claude_api(claude_key, processed_prompt)\n",
        "                    elapsed = time.time() - start_time\n",
        "\n",
        "                    table_response = response[:500] + \"...\" if len(response) > 500 else response\n",
        "                    results.append([\"Anthropic (Claude)\", table_response, round(elapsed, 2)])\n",
        "                    responses[\"Anthropic (Claude)\"] = response\n",
        "\n",
        "            # Mistral\n",
        "            if use_mistral:\n",
        "                if not mistral_key:\n",
        "                    results.append([\"Mistral AI\", \"❌ Error: API key not provided\", 0])\n",
        "                    responses[\"Mistral AI\"] = \"❌ Error: API key not provided\"\n",
        "                else:\n",
        "                    start_time = time.time()\n",
        "                    response = call_mistral_api(mistral_key, processed_prompt)\n",
        "                    elapsed = time.time() - start_time\n",
        "\n",
        "                    table_response = response[:500] + \"...\" if len(response) > 500 else response\n",
        "                    results.append([\"Mistral AI\", table_response, round(elapsed, 2)])\n",
        "                    responses[\"Mistral AI\"] = response\n",
        "\n",
        "            # Ollama (Local)\n",
        "            if use_ollama:\n",
        "                if not ollama_model:\n",
        "                    results.append([\"Ollama (Local)\", \"❌ Error: Model name not provided\", 0])\n",
        "                    responses[\"Ollama (Local)\"] = \"❌ Error: Model name not provided\"\n",
        "                else:\n",
        "                    start_time = time.time()\n",
        "                    response = call_ollama_api(ollama_model, processed_prompt, ollama_url)\n",
        "                    elapsed = time.time() - start_time\n",
        "\n",
        "                    table_response = response[:500] + \"...\" if len(response) > 500 else response\n",
        "                    results.append([\"Ollama (Local)\", table_response, round(elapsed, 2)])\n",
        "                    responses[\"Ollama (Local)\"] = response\n",
        "\n",
        "            # Create dropdown choices from actual models that were compared\n",
        "            model_choices = [row[0] for row in results]\n",
        "\n",
        "            # Generate performance metrics visualization\n",
        "            if len(results) > 0:\n",
        "                # Create a simple bar chart showing response times\n",
        "                response_times = [row[2] for row in results]\n",
        "                model_names = [row[0] for row in results]\n",
        "\n",
        "                # Generate an HTML table with metrics\n",
        "                metrics_table = f\"\"\"\n",
        "                <div style=\"margin: 20px 0; max-width: 800px;\">\n",
        "                    <h4>Response Time Comparison</h4>\n",
        "                    <table style=\"width: 100%; border-collapse: collapse; margin-top: 10px;\">\n",
        "                        <tr style=\"background-color: #f2f2f2;\">\n",
        "                            <th style=\"padding: 8px; text-align: left; border: 1px solid #ddd;\">Model</th>\n",
        "                            <th style=\"padding: 8px; text-align: left; border: 1px solid #ddd;\">Response Time (s)</th>\n",
        "                            <th style=\"padding: 8px; text-align: left; border: 1px solid #ddd;\">Relative Speed</th>\n",
        "                        </tr>\n",
        "                \"\"\"\n",
        "\n",
        "                # Find the fastest model for relative comparison\n",
        "                min_time = min([t for t in response_times if t > 0], default=1)\n",
        "\n",
        "                for i, model in enumerate(model_names):\n",
        "                    time_val = response_times[i]\n",
        "                    if time_val > 0:\n",
        "                        relative = f\"{time_val/min_time:.1f}x\"\n",
        "                        # Color coding: green for fastest, yellow for medium, red for slowest\n",
        "                        if time_val == min_time:\n",
        "                            bg_color = \"#e6ffe6\"  # Light green\n",
        "                        elif time_val < 2 * min_time:\n",
        "                            bg_color = \"#ffffcc\"  # Light yellow\n",
        "                        else:\n",
        "                            bg_color = \"#ffebe6\"  # Light red\n",
        "                    else:\n",
        "                        relative = \"N/A\"\n",
        "                        bg_color = \"#f2f2f2\"  # Light grey\n",
        "\n",
        "                    metrics_table += f\"\"\"\n",
        "                        <tr style=\"background-color: {bg_color};\">\n",
        "                            <td style=\"padding: 8px; text-align: left; border: 1px solid #ddd;\">{model}</td>\n",
        "                            <td style=\"padding: 8px; text-align: left; border: 1px solid #ddd;\">{time_val:.2f}</td>\n",
        "                            <td style=\"padding: 8px; text-align: left; border: 1px solid #ddd;\">{relative}</td>\n",
        "                        </tr>\n",
        "                    \"\"\"\n",
        "\n",
        "                metrics_table += \"\"\"\n",
        "                    </table>\n",
        "                    <p style=\"margin-top: 15px; font-style: italic;\">\n",
        "                        Note: Response times include API latency and may vary between runs.\n",
        "                        Consider multiple comparisons for reliable benchmarks.\n",
        "                    </p>\n",
        "                </div>\n",
        "                \"\"\"\n",
        "            else:\n",
        "                metrics_table = \"<p>No comparison data available.</p>\"\n",
        "\n",
        "            # If we have a detailed response for the first model, select it by default\n",
        "            initial_detailed_response = responses.get(model_choices[0], \"\") if model_choices else \"\"\n",
        "\n",
        "            return results, model_choices, initial_detailed_response, metrics_table, responses\n",
        "\n",
        "        # Function to show detailed response\n",
        "        def show_detailed_response(model, responses_dict):\n",
        "            return responses_dict.get(model, \"No response available for this model.\")\n",
        "\n",
        "        # Connect the load case study buttons\n",
        "        load_case_study_btn_comp1.click(lambda: CASE_STUDY_EN, inputs=[], outputs=prompt_input_comp)\n",
        "        load_case_study_btn_comp2.click(lambda: EDWARD_UNIVERSITY_CASE, inputs=[], outputs=prompt_input_comp)\n",
        "\n",
        "        # Connect the comparison button\n",
        "        results_state = gr.State({})  # State to store detailed responses\n",
        "\n",
        "        compare_button.click(\n",
        "            run_llm_comparison,\n",
        "            inputs=[\n",
        "                openai_key_comp, gemini_key_comp, claude_key_comp, mistral_key_comp,\n",
        "                ollama_url_comp, ollama_model_comp, prompt_input_comp,\n",
        "                use_openai_check, use_gemini_check, use_claude_check, use_mistral_check, use_ollama_check,\n",
        "                framework_choice_comp\n",
        "            ],\n",
        "            outputs=[\n",
        "                comparison_results,\n",
        "                selected_model_detail,\n",
        "                detailed_response,\n",
        "                metrics_html,\n",
        "                results_state\n",
        "            ]\n",
        "        )\n",
        "\n",
        "        # Connect the detailed view dropdown\n",
        "        selected_model_detail.change(\n",
        "            show_detailed_response,\n",
        "            inputs=[selected_model_detail, results_state],\n",
        "            outputs=detailed_response\n",
        "        )\n",
        "\n",
        "        # Example prompts\n",
        "        gr.Examples(\n",
        "            examples=[\n",
        "                [\"Identify the key interests of Armed Group Alpha based on the case study.\"],\n",
        "                [\"Generate 3 opening statements that could be used to approach the checkpoint commander.\"],\n",
        "                [\"What legal frameworks apply to humanitarian access in this scenario?\"],\n",
        "                [\"Create a one-page briefing on the negotiation strategy for field staff.\"]\n",
        "            ],\n",
        "            inputs=prompt_input_comp\n",
        "        )\n",
        "\n",
        "        # Comparison tips\n",
        "        gr.Markdown(\"\"\"\n",
        "        ### Comparison Tips:\n",
        "\n",
        "        - **Response Quality**: Compare depth of analysis, structure, relevance to humanitarian contexts\n",
        "        - **Speed**: Note the response time differences (affected by model size and API latency)\n",
        "        - **Framework Application**: See how different models interpret negotiation frameworks\n",
        "        - **Ethical Considerations**: Note how models handle complex ethical dilemmas in negotiations\n",
        "        - **Actionability**: Which model gives the most practical, implementable advice?\n",
        "        \"\"\")\n",
        "\n",
        "    # --- Tab: Cloud LLMs ---\n",
        "    with gr.Tab(\"☁️ Cloud LLMs Exploration\"):\n",
        "        gr.Markdown(\"## Interact with Cloud-Based LLMs (Functional)\")\n",
        "        gr.Markdown(\"Test different LLMs with your prompts or the case study. **API Keys are required.**\")\n",
        "\n",
        "        with gr.Row():\n",
        "            openai_key_input = gr.Textbox(label=\"🔑 OpenAI API Key\", type=\"password\", placeholder=\"Enter your OpenAI API key (sk-...)\")\n",
        "            gemini_key_input = gr.Textbox(label=\"🔑 Google AI (Gemini) API Key\", type=\"password\", placeholder=\"Enter your Google AI API key\")\n",
        "            anthropic_key_input = gr.Textbox(label=\"🔑 Anthropic (Claude) API Key\", type=\"password\", placeholder=\"Enter your Anthropic API key\")\n",
        "            mistral_key_input = gr.Textbox(label=\"🔑 Mistral AI API Key\", type=\"password\", placeholder=\"Enter your Mistral AI API key (optional)\")\n",
        "\n",
        "        with gr.Row():\n",
        "             llm_choice_cloud = gr.Dropdown(\n",
        "                label=\"Select LLM\",\n",
        "                choices=[\"ChatGPT (OpenAI)\", \"Gemini (Google)\", \"Claude (Anthropic)\", \"Mistral (Mistral AI)\"],\n",
        "                value=\"ChatGPT (OpenAI)\"\n",
        "            )\n",
        "             framework_choice = gr.Dropdown(\n",
        "                label=\"Apply Negotiation Framework (Optional)\",\n",
        "                choices=[\"None\", \"Island of Agreement\", \"BATNA/ZOPA\", \"Iceberg Analysis\", \"Stakeholder Matrix\", \"Multi-party Dynamics\", \"Success Factors\"],\n",
        "                value=\"None\"\n",
        "            )\n",
        "\n",
        "        prompt_input_cloud = gr.Textbox(label=\"📝 Enter Prompt\", lines=7, placeholder=\"Enter your prompt here, or use the case study text.\")\n",
        "        with gr.Row():\n",
        "            load_case_study_btn_cloud1 = gr.Button(\"Load IDP Camp Case\")\n",
        "            load_case_study_btn_cloud2 = gr.Button(\"Load University Crisis Case\")\n",
        "        submit_button_cloud = gr.Button(\"🚀 Send Prompt to Cloud LLM\", variant=\"primary\")\n",
        "        output_cloud = gr.Textbox(label=\"LLM Response\", lines=15, interactive=False)\n",
        "\n",
        "        # --- Cloud LLM Logic ---\n",
        "        def cloud_llm_interface(api_openai, api_gemini, api_anthropic, api_mistral, choice, framework, prompt):\n",
        "            if not prompt:\n",
        "                 return \"⚠️ Please enter a prompt.\"\n",
        "\n",
        "            # Apply framework to the prompt if selected\n",
        "            processed_prompt = apply_negotiation_framework(framework, prompt)\n",
        "            if framework.lower() != 'none':\n",
        "                 print(f\"ℹ️ Applying framework '{framework}'. Modified prompt:\\n{processed_prompt[:300]}...\") # Log modified prompt\n",
        "\n",
        "            result = f\"❌ Error: LLM choice '{choice}' not recognized.\" # Default error\n",
        "\n",
        "            if choice == \"ChatGPT (OpenAI)\":\n",
        "                result = call_openai_api(api_openai, processed_prompt)\n",
        "            elif choice == \"Gemini (Google)\":\n",
        "                result = call_gemini_api(api_gemini, processed_prompt)\n",
        "            elif choice == \"Claude (Anthropic)\":\n",
        "                result = call_claude_api(api_anthropic, processed_prompt)\n",
        "            elif choice == \"Mistral (Mistral AI)\":\n",
        "                result = call_mistral_api(api_mistral, processed_prompt)\n",
        "\n",
        "            return result\n",
        "\n",
        "        load_case_study_btn_cloud1.click(lambda: CASE_STUDY_EN, inputs=[], outputs=prompt_input_cloud)\n",
        "        load_case_study_btn_cloud2.click(lambda: EDWARD_UNIVERSITY_CASE, inputs=[], outputs=prompt_input_cloud)\n",
        "\n",
        "        submit_button_cloud.click(\n",
        "            cloud_llm_interface,\n",
        "            inputs=[openai_key_input, gemini_key_input, anthropic_key_input, mistral_key_input, llm_choice_cloud, framework_choice, prompt_input_cloud],\n",
        "            outputs=output_cloud\n",
        "        )\n",
        "\n",
        "        gr.Examples(\n",
        "            examples=[\n",
        "                [\"ChatGPT (OpenAI)\", \"None\", \"Based on the case study, what are the 3 main interests of Armed Group Alpha?\"],\n",
        "                [\"Gemini (Google)\", \"Island of Agreement\", CASE_STUDY_EN],\n",
        "                [\"Claude (Anthropic)\", \"BATNA/ZOPA\", \"Scenario: Negotiating release of detained staff member. Org wants immediate release. Counterpart wants prisoner exchange.\"],\n",
        "                [\"Mistral (Mistral AI)\", \"None\", \"Draft a neutral opening statement for the first meeting with Armed Group Alpha based on the case study.\"]\n",
        "            ],\n",
        "            inputs=[llm_choice_cloud, framework_choice, prompt_input_cloud],\n",
        "            outputs=output_cloud,\n",
        "            fn=cloud_llm_interface, # Function to call for examples\n",
        "            cache_examples=False # Avoid caching API calls\n",
        "        )\n",
        "        gr.Markdown(\"---\")\n",
        "        gr.Markdown(\"### Benchmarking & Frameworks\")\n",
        "        gr.Markdown(\"The 'Apply Negotiation Framework' dropdown modifies your prompt to ask the LLM for specific analysis structures (IoA, BATNA/ZOPA). Live benchmarking between models is complex; evaluate responses based on relevance, coherence, and actionable insights for your negotiation needs.\")\n",
        "\n",
        "\n",
        "    # --- Tab: Local LLMs (Ollama) ---\n",
        "    with gr.Tab(\"💻 Local LLMs (Ollama Connection)\"):\n",
        "        gr.Markdown(\"## Connect to Local LLMs via Ollama (Functional)\")\n",
        "        gr.Markdown(\"**Requirement:** You MUST have Ollama installed and running on your local machine for this tab to work.\")\n",
        "        gr.HTML(\"\"\"\n",
        "        <ul>\n",
        "            <li>Download and install Ollama from <a href='https://ollama.com/' target='_blank'>ollama.com</a>.</li>\n",
        "            <li>Pull models using the terminal: <code>ollama pull model_name</code> (e.g., <code>ollama pull llama3:8b</code>, <code>ollama pull mistral:7b</code>, <code>ollama pull gemma:2b</code>).</li>\n",
        "            <li>Ensure Ollama is running in the background.</li>\n",
        "            <li><b>Connection Issues?</b> If Gradio is running in Colab, connecting to <code>localhost:11434</code> might fail. Consider running this Gradio script locally on your machine, or setting up tunneling (advanced).</li>\n",
        "        </ul>\n",
        "        \"\"\")\n",
        "        with gr.Row():\n",
        "            # Common Ollama models - user can also type a custom one\n",
        "            ollama_model_input = gr.Dropdown(\n",
        "                label=\"Select or Enter Local Ollama Model Name\",\n",
        "                choices=[\"llama3:8b\", \"mistral:7b\", \"gemma:2b\", \"gemma:7b\", \"phi3:mini\"],\n",
        "                value=\"gemma:2b\",\n",
        "                allow_custom_value=True\n",
        "            )\n",
        "            ollama_url_input = gr.Textbox(label=\"Ollama API URL\", value=\"http://localhost:11434\", placeholder=\"Usually http://localhost:11434\")\n",
        "\n",
        "        prompt_input_ollama = gr.Textbox(label=\"📝 Enter Prompt for Local LLM\", lines=7, placeholder=\"Enter your prompt here...\")\n",
        "        with gr.Row():\n",
        "            load_case_study_btn_ollama1 = gr.Button(\"Load IDP Camp Case\")\n",
        "            load_case_study_btn_ollama2 = gr.Button(\"Load University Crisis Case\")\n",
        "        submit_button_ollama = gr.Button(\"🚀 Send Prompt to Local Ollama\", variant=\"primary\")\n",
        "        output_ollama = gr.Textbox(label=\"Ollama Response\", lines=15, interactive=False)\n",
        "\n",
        "        # --- Ollama Logic ---\n",
        "        def ollama_interface(model, url, prompt):\n",
        "            if not prompt:\n",
        "                return \"⚠️ Please enter a prompt.\"\n",
        "            if not model:\n",
        "                 return \"❌ Please select or enter an Ollama model name.\"\n",
        "            if not url:\n",
        "                 return \"❌ Please enter the Ollama API URL.\"\n",
        "\n",
        "            # Try the API method first\n",
        "            try:\n",
        "                result = call_ollama_api(model, prompt, url)\n",
        "                # If result starts with error message, try subprocess method as fallback\n",
        "                if result.startswith(\"❌\"):\n",
        "                    print(\"API method failed, trying subprocess method...\")\n",
        "                    subprocess_result = call_ollama_subprocess(model, prompt)\n",
        "                    if not subprocess_result.startswith(\"❌\"):\n",
        "                        return subprocess_result + \"\\n\\n(Note: Used subprocess method as API method failed)\"\n",
        "                return result\n",
        "            except Exception as e:\n",
        "                # If API method fails completely, try subprocess\n",
        "                print(f\"API method failed with exception: {e}, trying subprocess method...\")\n",
        "                try:\n",
        "                    return call_ollama_subprocess(model, prompt)\n",
        "                except Exception as sub_e:\n",
        "                    return f\"❌ Both API and subprocess methods failed.\\nAPI error: {e}\\nSubprocess error: {sub_e}\"\n",
        "\n",
        "        load_case_study_btn_ollama1.click(lambda: CASE_STUDY_EN, inputs=[], outputs=prompt_input_ollama)\n",
        "        load_case_study_btn_ollama2.click(lambda: EDWARD_UNIVERSITY_CASE, inputs=[], outputs=prompt_input_ollama)\n",
        "\n",
        "        submit_button_ollama.click(\n",
        "            ollama_interface,\n",
        "            inputs=[ollama_model_input, ollama_url_input, prompt_input_ollama],\n",
        "            outputs=output_ollama\n",
        "        )\n",
        "\n",
        "        gr.Examples(\n",
        "            examples=[\n",
        "                [\"gemma:2b\", \"http://localhost:11434\", \"What are 3 key negotiation strategies I could use with Armed Group Alpha?\"],\n",
        "                [\"llama3:8b\", \"http://localhost:11434\", \"Summarize the key challenges in the provided case study.\"],\n",
        "                [\"mistral:7b\", \"http://localhost:11434\", \"Generate 3 potential questions to ask Armed Group Alpha to understand their security concerns better.\"]\n",
        "            ],\n",
        "            inputs=[ollama_model_input, ollama_url_input, prompt_input_ollama],\n",
        "            outputs=output_ollama,\n",
        "            fn=ollama_interface,\n",
        "            cache_examples=False # Ollama responses can vary\n",
        "        )\n",
        "        gr.Markdown(\"---\")\n",
        "        gr.Markdown(\"### Alternative Local Tools\")\n",
        "        gr.Markdown(\"The original notebook also mentions **AnythingLLM**. It provides a user interface for interacting with local models and documents, often using Ollama or other backends. Explore it at [useanything.com](https://useanything.com/).\")\n",
        "\n",
        "\n",
        "    # --- Tab: Automation (n8n) ---\n",
        "    with gr.Tab(\"⚙️ Automation (n8n Webhook Trigger)\"):\n",
        "        gr.Markdown(\"## Trigger n8n Automation Workflows (Functional)\")\n",
        "        gr.Markdown(\"**Requirement:** You need an n8n instance (cloud or self-hosted) with a workflow set up to be triggered by a Webhook node.\")\n",
        "        gr.HTML(\"\"\"\n",
        "        <ul>\n",
        "            <li>Create a workflow in n8n.</li>\n",
        "            <li>Add a 'Webhook' node as the trigger.</li>\n",
        "            <li>Copy the 'Test URL' or 'Production URL' provided by the Webhook node.</li>\n",
        "            <li>Ensure your n8n instance is running and accessible from where you run this script.</li>\n",
        "        </ul>\n",
        "        <p>You can use this to send data (e.g., analysis results, scenario summaries) from this toolkit to n8n to trigger further actions like updating databases, sending notifications, etc.</p>\n",
        "        \"\"\")\n",
        "\n",
        "        n8n_webhook_url_input = gr.Textbox(label=\"🔗 n8n Webhook URL\", placeholder=\"Paste your n8n webhook Test or Production URL here\")\n",
        "        n8n_payload_input = gr.Textbox(label=\"📄 Payload Data (JSON format)\", lines=8, value='{\\n  \"source\": \"LLM Toolkit Gradio App\",\\n  \"event\": \"Scenario Analysis Completed\",\\n  \"data\": {\\n    \"scenario_summary\": \"Negotiating access for IDP camp...\",\\n    \"key_finding\": \"High mistrust level detected.\"\\n  },\\n  \"timestamp\": \"' + datetime.now().isoformat() + '\"\\n}')\n",
        "        submit_button_n8n = gr.Button(\"🚀 Trigger n8n Webhook\", variant=\"primary\")\n",
        "        output_n8n = gr.Textbox(label=\"n8n Response / Status\", lines=5, interactive=False)\n",
        "\n",
        "        # --- n8n Logic ---\n",
        "        def n8n_interface(url, payload):\n",
        "            if not url:\n",
        "                return \"⚠️ Please enter the n8n webhook URL.\"\n",
        "            if not payload:\n",
        "                 return \"⚠️ Please enter the JSON payload.\"\n",
        "\n",
        "            # Call the actual n8n trigger function\n",
        "            result = trigger_n8n_webhook(url, payload)\n",
        "            return result\n",
        "\n",
        "        submit_button_n8n.click(\n",
        "            n8n_interface,\n",
        "            inputs=[n8n_webhook_url_input, n8n_payload_input],\n",
        "            outputs=output_n8n\n",
        "        )\n",
        "        gr.Markdown(\"---\")\n",
        "        gr.Markdown(\"### Automation Ideas\")\n",
        "        gr.Markdown(\"Connect LLM analysis results to: update a negotiation tracker (Airtable, Sheets), send summaries via Email/Slack, create tasks in project management tools, generate draft reports.\")\n",
        "        gr.Markdown(\"Other automation platforms like **Make.com** and **Zapier** offer similar webhook capabilities.\")\n",
        "\n",
        "\n",
        "    # --- Tab: Interface Generation ---\n",
        "    with gr.Tab(\"🎨 Interface Generation\"):\n",
        "        gr.Markdown(\"## Generating Interfaces with LLMs & Examples\")\n",
        "        gr.Markdown(\"LLMs can help generate code for simple web interfaces. You can use the Cloud LLMs tab to ask models (like Claude, GPT-4, Gemini) to create HTML, CSS, and JavaScript for specific tools.\")\n",
        "\n",
        "        gr.Markdown(\"### Example Prompts for LLMs\")\n",
        "        with gr.Accordion(\"Show Example Prompts\", open=False):\n",
        "            gr.Code(language=\"markdown\", value=\"\"\"\n",
        "**Prompt 1: Negotiation Planning Tool**\n",
        "\"Create a simple HTML page using Bootstrap 5 CSS. It should have input fields for: Negotiation Goal, Key Counterparts, My BATNA, Their Estimated BATNA, Potential Options. Include a button to save or print the plan (basic JS alert is fine).\"\n",
        "\n",
        "**Prompt 2: Stakeholder Mapping Interface**\n",
        "\"Generate HTML and CSS for a stakeholder mapping tool. Use cards for each stakeholder. Each card should have fields for: Name, Role, Stated Position, Likely Interests, Influence Level (1-5), Relationship (Ally/Neutral/Blocker). Allow adding new stakeholder cards dynamically using JavaScript.\"\n",
        "\n",
        "**Prompt 3: Island of Agreement Tool (like the one below)**\n",
        "\"Create an HTML page using Bootstrap 5 for the 'Island of Agreement' negotiation framework. It needs four columns: Contested Facts, Agreed Facts, Divergent Norms/Interests, Convergent Norms/Interests. Each column should allow adding text items. Items should be movable between columns and deletable using JavaScript.\"\n",
        "            \"\"\")\n",
        "\n",
        "        gr.Markdown(\"### Example: Island of Agreement Tool (Embedded)\")\n",
        "        gr.Markdown(\"Below is the interactive 'Island of Agreement' tool generated based on the notebook's code, embedded directly here.\")\n",
        "        gr.HTML(ioa_interface_html) # Embed the HTML interface\n",
        "\n",
        "        gr.Markdown(\"---\")\n",
        "        gr.Markdown(\"### Code for the IoA Tool Above\")\n",
        "        with gr.Accordion(\"Show HTML/CSS/JS Code\", open=False):\n",
        "             gr.Code(language=\"html\", value=ioa_interface_html)\n",
        "\n",
        "\n",
        "    # --- Tab: Voice Synthesis (ElevenLabs) ---\n",
        "    with gr.Tab(\"🎙️ Voice Synthesis (ElevenLabs)\"):\n",
        "        gr.Markdown(\"## Generate Audio Briefings with ElevenLabs (Functional)\")\n",
        "        gr.Markdown(\"Convert text to speech for briefings, accessibility, or multilingual communication. **Requires an ElevenLabs API Key.**\")\n",
        "\n",
        "        elevenlabs_api_key_input = gr.Textbox(label=\"🔑 ElevenLabs API Key\", type=\"password\", placeholder=\"Enter your ElevenLabs API key\")\n",
        "        # Common voices - check ElevenLabs website for full list and IDs if needed\n",
        "        elevenlabs_voice_id_input = gr.Dropdown(\n",
        "            label=\"Select Voice (Name or ID)\",\n",
        "            choices=[\"Rachel\", \"Adam\", \"Antoni\", \"Arnold\", \"Bella\", \"Domi\", \"Elli\", \"Josh\", \"Nicole\", \"Sarah\", \"Jeremy\"], # Add more or use IDs\n",
        "            value=\"Rachel\",\n",
        "            allow_custom_value=True # Allow entering voice IDs directly\n",
        "        )\n",
        "        text_to_speak_input = gr.Textbox(label=\"📝 Text to Synthesize\", lines=8, placeholder=\"Enter the text to convert to audio...\")\n",
        "\n",
        "        with gr.Row():\n",
        "            load_case_study_btn_eleven1 = gr.Button(\"Load IDP Camp Briefing\")\n",
        "            load_case_study_btn_eleven2 = gr.Button(\"Load University Crisis Briefing\")\n",
        "\n",
        "        # Sample briefings\n",
        "        idp_briefing = \"\"\"\n",
        "        Field Security Briefing: Northern Province IDP Camp Access\n",
        "\n",
        "        Current situation: Armed Group Alpha controls checkpoints around the IDP camp. Approximately 20,000 displaced civilians require urgent humanitarian assistance including medical care, food, and water.\n",
        "\n",
        "        Key contacts: Commander Khalid is the primary checkpoint authority. Local community leaders Fatima Hassan and Ibrahim Nur can facilitate communication.\n",
        "\n",
        "        Security protocols: All vehicles must display organizational emblems. Staff must carry identification. No photos at checkpoints. Maintain radio contact with base at all times.\n",
        "\n",
        "        Contingency plan: If access is denied, return to base immediately and report to security coordinator. Do not attempt negotiation without proper authorization.\n",
        "        \"\"\"\n",
        "\n",
        "        university_briefing = \"\"\"\n",
        "        Security Update: Edward University Campus Crisis\n",
        "\n",
        "        Current situation: Student occupation of administration building continues with increased tensions. External activists have joined protests. Media presence is extensive.\n",
        "\n",
        "        Key parties: University administration seeks immediate evacuation. Moderate student leaders willing to negotiate. External activists pursuing broader agenda.\n",
        "\n",
        "        Security protocols: Maintain neutral stance. Avoid crossing police lines. Carry identification at all times. Do not engage with media without authorization.\n",
        "\n",
        "        Authorized contacts: Dean Roberts is our primary university contact. Student representative Sarah Chen is moderate faction liaison. Avoid direct engagement with radical elements.\n",
        "        \"\"\"\n",
        "\n",
        "        # Voice settings\n",
        "        with gr.Accordion(\"Voice Settings\", open=False):\n",
        "            stability_slider = gr.Slider(minimum=0.0, maximum=1.0, value=0.7, step=0.1, label=\"Stability\")\n",
        "            similarity_boost_slider = gr.Slider(minimum=0.0, maximum=1.0, value=0.7, step=0.1, label=\"Similarity Boost\")\n",
        "\n",
        "        generate_audio_button = gr.Button(\"🔊 Generate Audio\", variant=\"primary\")\n",
        "\n",
        "        audio_output = gr.Audio(label=\"Generated Audio\", type=\"filepath\") # Use filepath to handle the generated file\n",
        "        status_output_eleven = gr.Textbox(label=\"Status\", lines=2, interactive=False)\n",
        "\n",
        "        # Add fallback option for local TTS\n",
        "        use_local_tts = gr.Checkbox(label=\"Use local TTS (if no ElevenLabs API key)\", value=False)\n",
        "\n",
        "        # --- ElevenLabs Logic ---\n",
        "        def elevenlabs_interface(api_key, voice, text, stability, similarity_boost, use_local):\n",
        "             if not text:\n",
        "                 return None, \"⚠️ Please enter text to synthesize.\"\n",
        "\n",
        "             # Check if local TTS fallback should be used\n",
        "             if not api_key or use_local:\n",
        "                 # Use local TTS\n",
        "                 audio_file_path, status_msg = generate_local_tts(text)\n",
        "                 return audio_file_path, status_msg\n",
        "\n",
        "             # Call the ElevenLabs function with enhanced parameters\n",
        "             audio_file_path, status_msg = generate_elevenlabs_audio(\n",
        "                 api_key, text, voice, stability=stability, similarity_boost=similarity_boost\n",
        "             )\n",
        "             return audio_file_path, status_msg\n",
        "\n",
        "        load_case_study_btn_eleven1.click(lambda: idp_briefing, inputs=[], outputs=text_to_speak_input)\n",
        "        load_case_study_btn_eleven2.click(lambda: university_briefing, inputs=[], outputs=text_to_speak_input)\n",
        "\n",
        "        generate_audio_button.click(\n",
        "            elevenlabs_interface,\n",
        "            inputs=[elevenlabs_api_key_input, elevenlabs_voice_id_input, text_to_speak_input,\n",
        "                   stability_slider, similarity_boost_slider, use_local_tts],\n",
        "            outputs=[audio_output, status_output_eleven]\n",
        "        )\n",
        "\n",
        "        gr.Examples(\n",
        "            examples=[\n",
        "                [\"Rachel\", \"Briefing summary for tomorrow's meeting: Confirm security protocols and beneficiary lists.\"],\n",
        "                [\"Adam\", \"Key negotiation points: Unrestricted access, respect for humanitarian principles, staff protection.\"]\n",
        "            ],\n",
        "            inputs=[elevenlabs_voice_id_input, text_to_speak_input],\n",
        "            outputs=[audio_output, status_output_eleven],\n",
        "            fn=lambda voice, text: elevenlabs_interface(\"\", voice, text, 0.7, 0.7, True),  # Use local TTS for examples\n",
        "            cache_examples=False\n",
        "        )\n",
        "        gr.Markdown(\"---\")\n",
        "        gr.Markdown(\"### Integration Ideas\")\n",
        "        gr.Markdown(\"\"\"\n",
        "        * **Pre-meeting Briefings:** Audio versions of prep docs for listening on the go.\n",
        "        * **Multilingual Comms:** Convert updates to audio in team members' languages.\n",
        "        * **Accessibility:** Hands-free access to analysis for field staff.\n",
        "        * **Automation:** Connect via n8n to auto-generate audio when analysis is ready.\n",
        "        \"\"\")\n",
        "\n",
        "\n",
        "    # --- Tab: Integrated Assistant ---\n",
        "    with gr.Tab(\"🤝 Integrated Negotiation Assistant\"):\n",
        "        gr.Markdown(\"## Humanitarian Negotiation Assistant (Functional)\")\n",
        "        gr.Markdown(\"Get comprehensive analysis of a negotiation scenario using a selected LLM. **API Keys required for Cloud/Local LLMs.**\")\n",
        "\n",
        "        gr.Markdown(\"### 1. Input Scenario & Choose LLM\")\n",
        "        with gr.Row():\n",
        "             assistant_llm_choice = gr.Dropdown(\n",
        "                label=\"Select Analysis LLM\",\n",
        "                choices=[\"ChatGPT (OpenAI)\", \"Gemini (Google)\", \"Claude (Anthropic)\", \"Mistral (Mistral AI)\", \"Ollama (Local)\"],\n",
        "                value=\"ChatGPT (OpenAI)\"\n",
        "            )\n",
        "             # Input for Ollama model needed only if Ollama is chosen\n",
        "             assistant_ollama_model = gr.Textbox(label=\"Ollama Model Name (if Local)\", placeholder=\"e.g., llama3:8b\", visible=False) # Initially hidden\n",
        "\n",
        "        scenario_input_assistant = gr.Textbox(label=\"📝 Negotiation Scenario\", lines=10, value=CASE_STUDY_EN)\n",
        "\n",
        "        with gr.Row():\n",
        "            load_case_study_btn_asst1 = gr.Button(\"Load IDP Camp Case\")\n",
        "            load_case_study_btn_asst2 = gr.Button(\"Load University Crisis Case\")\n",
        "\n",
        "        gr.Markdown(\"### 2. Provide API Keys (if needed)\")\n",
        "        with gr.Accordion(\"API Keys (Required for selected LLM)\", open=False):\n",
        "             with gr.Row():\n",
        "                openai_key_input_asist = gr.Textbox(label=\"🔑 OpenAI API Key\", type=\"password\")\n",
        "                gemini_key_input_asist = gr.Textbox(label=\"🔑 Gemini API Key\", type=\"password\")\n",
        "                anthropic_key_input_asist = gr.Textbox(label=\"🔑 Claude API Key\", type=\"password\")\n",
        "                mistral_key_input_asist = gr.Textbox(label=\"🔑 Mistral API Key\", type=\"password\")\n",
        "                # No key needed for Ollama, but URL might be relevant\n",
        "                ollama_url_input_asist = gr.Textbox(label=\"Ollama API URL (if Local)\", value=\"http://localhost:11434\")\n",
        "\n",
        "        # Add analysis framework selection\n",
        "        assistant_framework = gr.Radio(\n",
        "            label=\"🧠 Analysis Framework\",\n",
        "            choices=[\"Basic Analysis\", \"Island of Agreement\", \"BATNA/ZOPA\", \"Complete Crisis Framework\"],\n",
        "            value=\"Basic Analysis\",\n",
        "            info=\"Choose depth of analysis. Complete Crisis Framework works best with Claude or GPT-4.\"\n",
        "        )\n",
        "\n",
        "        analyze_button_assistant = gr.Button(\"💡 Analyze Scenario\", variant=\"primary\")\n",
        "\n",
        "        gr.Markdown(\"### 3. Analysis Results\")\n",
        "        # Use Markdown for structured output, potentially with HTML for better formatting if needed\n",
        "        analysis_output_assistant = gr.Markdown(label=\"Scenario Analysis\")\n",
        "\n",
        "        # --- Assistant Logic ---\n",
        "        def assistant_interface(llm_choice, ollama_model, scenario, api_openai, api_gemini, api_anthropic, api_mistral, ollama_url, framework_choice):\n",
        "            if not scenario:\n",
        "                return \"⚠️ Please enter a negotiation scenario.\"\n",
        "\n",
        "            # Build the structured prompt based on selected framework\n",
        "            if framework_choice == \"Basic Analysis\":\n",
        "                structured_prompt = build_assistant_prompt(scenario)\n",
        "            elif framework_choice == \"Island of Agreement\":\n",
        "                structured_prompt = apply_negotiation_framework(\"Island of Agreement\", scenario)\n",
        "            elif framework_choice == \"BATNA/ZOPA\":\n",
        "                structured_prompt = apply_negotiation_framework(\"BATNA/ZOPA\", scenario)\n",
        "            elif framework_choice == \"Complete Crisis Framework\":\n",
        "                structured_prompt = build_crisis_analysis_prompt(scenario, \"text\")\n",
        "            else:\n",
        "                # Default to basic analysis\n",
        "                structured_prompt = build_assistant_prompt(scenario)\n",
        "\n",
        "            result = f\"❌ Error: LLM choice '{llm_choice}' not recognized.\" # Default error\n",
        "\n",
        "            if llm_choice == \"ChatGPT (OpenAI)\":\n",
        "                system_message = \"You are a humanitarian negotiation expert specializing in crisis analysis and strategic engagement.\"\n",
        "                result = call_openai_api(api_openai, structured_prompt, system_message=system_message)\n",
        "            elif llm_choice == \"Gemini (Google)\":\n",
        "                result = call_gemini_api(api_gemini, structured_prompt)\n",
        "            elif llm_choice == \"Claude (Anthropic)\":\n",
        "                system_message = \"You are a humanitarian negotiation expert specializing in crisis analysis and strategic engagement.\"\n",
        "                result = call_claude_api(api_anthropic, structured_prompt, system_message=system_message)\n",
        "            elif llm_choice == \"Mistral (Mistral AI)\":\n",
        "                result = call_mistral_api(api_mistral, structured_prompt)\n",
        "            elif llm_choice == \"Ollama (Local)\":\n",
        "                 if not ollama_model:\n",
        "                     return \"❌ Please enter the Ollama Model Name when 'Ollama (Local)' is selected.\"\n",
        "                 result = call_ollama_api(ollama_model, structured_prompt, ollama_url)\n",
        "\n",
        "            # Return result formatted as Markdown\n",
        "            return result\n",
        "\n",
        "        # Show/hide Ollama model input based on LLM choice\n",
        "        def toggle_ollama_input(choice):\n",
        "            if choice == \"Ollama (Local)\":\n",
        "                return gr.update(visible=True)\n",
        "            else:\n",
        "                return gr.update(visible=False)\n",
        "\n",
        "        assistant_llm_choice.change(toggle_ollama_input, inputs=assistant_llm_choice, outputs=assistant_ollama_model)\n",
        "\n",
        "        load_case_study_btn_asst1.click(lambda: CASE_STUDY_EN, inputs=[], outputs=scenario_input_assistant)\n",
        "        load_case_study_btn_asst2.click(lambda: EDWARD_UNIVERSITY_CASE, inputs=[], outputs=scenario_input_assistant)\n",
        "\n",
        "        analyze_button_assistant.click(\n",
        "            assistant_interface,\n",
        "            inputs=[\n",
        "                assistant_llm_choice, assistant_ollama_model, scenario_input_assistant,\n",
        "                openai_key_input_asist, gemini_key_input_asist, anthropic_key_input_asist, mistral_key_input_asist,\n",
        "                ollama_url_input_asist, assistant_framework\n",
        "            ],\n",
        "            outputs=analysis_output_assistant\n",
        "        )\n",
        "\n",
        "\n",
        "    # --- Tab: Resources & Glossary ---\n",
        "    with gr.Tab(\"📚 Resources & Glossary\"):\n",
        "        gr.Markdown(\"## Additional Resources and Glossary\")\n",
        "        # Add content from the notebook's resource section here\n",
        "        gr.Markdown(\"\"\"\n",
        "        ### Key Terms Glossary\n",
        "        * **LLM (Large Language Model):** AI model trained on vast text data to understand and generate human-like language (e.g., GPT-4, Gemini, Claude, Llama).\n",
        "        * **API (Application Programming Interface):** A way for different software programs to communicate with each other. Used here to access cloud LLMs.\n",
        "        * **Cloud LLM:** Models hosted by companies (OpenAI, Google, Anthropic) accessed via the internet/API.\n",
        "        * **Local LLM:** Models run entirely on your own computer, offering privacy and offline capability.\n",
        "        * **Ollama:** A tool that simplifies running local LLMs.\n",
        "        * **MTP (Mini Task Process):** Structured prompt templates with predefined parameters for consistent outputs.\n",
        "        * **n8n / Make / Zapier:** Workflow automation platforms to connect different apps and services.\n",
        "        * **Webhook:** A web address that can receive data, often used to trigger automation workflows.\n",
        "        * **Gradio / Streamlit:** Python libraries for building simple web interfaces for data science and AI applications.\n",
        "        * **ElevenLabs:** A platform for realistic AI voice synthesis (Text-to-Speech).\n",
        "        * **Prompt Engineering:** The art and science of crafting effective inputs (prompts) to get desired outputs from LLMs.\n",
        "        * **BATNA (Best Alternative To a Negotiated Agreement):** What a party will do if they fail to reach an agreement.\n",
        "        * **ZOPA (Zone Of Possible Agreement):** The range where an agreement is possible that is acceptable to all parties.\n",
        "        * **Island of Agreement:** A framework focusing on identifying common ground (agreed facts, convergent norms) alongside differences (contested facts, divergent norms).\n",
        "        * **Iceberg Analysis:** Technique to discover underlying interests beneath stated positions in negotiations.\n",
        "        * **Stakeholder Matrix:** Tool for mapping actors by their power, legitimacy, and urgency in a crisis.\n",
        "        * **Complete Crisis Framework:** A comprehensive 9-part analytical approach for complex humanitarian crisis negotiations.\n",
        "\n",
        "        ### Useful Links\n",
        "        * [Ollama](https://ollama.com/)\n",
        "        * [n8n.io](https://n8n.io/)\n",
        "        * [OpenAI API](https://platform.openai.com/)\n",
        "        * [Google AI Studio (Gemini)](https://aistudio.google.com/)\n",
        "        * [Anthropic (Claude)](https://www.anthropic.com/)\n",
        "        * [Mistral AI](https://mistral.ai/)\n",
        "        * [ElevenLabs](https://elevenlabs.io/)\n",
        "        * [Gradio](https://www.gradio.app/)\n",
        "        * [AnythingLLM](https://useanything.com/)\n",
        "        * [CCHN Field Manual](https://frontline-negotiations.org/resources/cchn-field-manual/)\n",
        "        * [Humanitarian Negotiation Toolkit](https://www.alnap.org/help-library/humanitarian-negotiation-a-handbook-for-securing-access-assistance-and-protection-for)\n",
        "        * [Island of Agreement Framework](https://www.usip.org/publications/2010/10/negotiating-forward-consensus-building)\n",
        "        * [Harvard Negotiation Project](https://www.pon.harvard.edu/research_projects/harvard-negotiation-project/)\n",
        "        \"\"\")\n",
        "\n",
        "        gr.Markdown(\"### Recommended YouTube Channels\")\n",
        "        gr.Markdown(\"\"\"\n",
        "        * **Fireship 🔥** – Quick tutorials on Ollama, Gemini, and modern AI tools: [Fireship](https://www.youtube.com/c/Fireship)\n",
        "        * **CodeEmporium** – Great tutorials on ElevenLabs API and voice synthesis: [CodeEmporium](https://www.youtube.com/channel/UC5k_PVN_SYcNBTSQ-TtCnpQ)\n",
        "        * **AssemblyAI** – Excellent content on voice AI and NLP tools: [AssemblyAI](https://www.youtube.com/c/AssemblyAI)\n",
        "        * **Data School** – Tutorials on n8n automation and Hugging Face: [Data School](https://www.youtube.com/c/dataschool)\n",
        "        * **Humanitarian Negotiations** – Harvard's Program on Negotiation: [PON](https://www.youtube.com/playlist?list=PLvSHJahq4Z-T9yEr3I1b5wDdKP-VBxcYY)\n",
        "        \"\"\")\n",
        "\n",
        "print(\"✅ Gradio interface created.\")\n",
        "\n",
        "\n",
        "# @title Cell 4: Launch Gradio Application\n",
        "# ---\n",
        "# Executes this cell to start the Gradio application.\n",
        "# A public link will be generated (if share=True) to access the interface.\n",
        "# ---\n",
        "print(\"🚀 Launching Gradio application...\")\n",
        "# share=True generates a public temporary link (valid for ~72h)\n",
        "# debug=True shows more detailed error messages in the console\n",
        "app.launch(share=True, debug=True)"
      ]
    }
  ]
}